{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MusicGen-Large Finetuning Loop (Sequential Processing) - Transformers Version\n",
                "\n",
                "このノートブックは、大規模なデータセットをZIPファイル単位で順次処理（解凍→学習→削除）しながらMusicGen-Largeをファインチューニングします。\n",
                "Hugging Face Transformersライブラリを使用します。\n",
                "\n",
                "## 前提条件\n",
                "1. Google Driveに以下のデータがあること\n",
                "   - `MyData/Archive_wavs/metadata.jsonl`: 全データのメタデータ\n",
                "   - `MyData/Archive_wavs/archive_batch_xxxx.zip`: 音声データのZIPファイル群\n",
                "2. A100 GPU推奨（VRAM容量のため）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d63c9361",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. 環境設定とライブラリインストール\n",
                "import os\n",
                "import subprocess\n",
                "import sys\n",
                "\n",
                "print(\"Installing libraries...\")\n",
                "\n",
                "# CUDA 12.6対応のPyTorch (Nightly or Pre-release)\n",
                "# 注意: ユーザー指定によりCUDA 12.6をターゲットにします。\n",
                "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu126\n",
                "\n",
                "# Hugging Face Libraries\n",
                "!pip install -U git+https://github.com/huggingface/transformers.git\n",
                "!pip install -U datasets accelerate bitsandbytes\n",
                "\n",
                "print(\"Installation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d92f8c8e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Google Drive マウント\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1f847a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. パスと設定の定義\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# --- ユーザー設定エリア ---\n",
                "DRIVE_ROOT = Path('/content/drive/MyDrive')\n",
                "DATA_ROOT = DRIVE_ROOT / 'MyData/Archive_wavs'\n",
                "METADATA_PATH = DATA_ROOT / 'metadata.jsonl'\n",
                "ZIP_DIR = DATA_ROOT\n",
                "\n",
                "# 出力先（チェックポイント保存場所）\n",
                "OUTPUT_DIR = DRIVE_ROOT / 'MusicGen_Finetuning_Output'\n",
                "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "# 一時作業ディレクトリ（Colabローカル）\n",
                "TEMP_WORK_DIR = Path('/content/temp_work')\n",
                "TEMP_DATA_DIR = TEMP_WORK_DIR / 'data'\n",
                "\n",
                "TEMP_DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "print(f\"Metadata: {METADATA_PATH}\")\n",
                "print(f\"Zip Dir: {ZIP_DIR}\")\n",
                "print(f\"Output Dir: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "54963656",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. ヘルパー関数の定義\n",
                "import json\n",
                "import shutil\n",
                "import subprocess\n",
                "import glob\n",
                "import torchaudio\n",
                "from datasets import load_dataset, Audio\n",
                "\n",
                "def extract_zip(zip_path, extract_to):\n",
                "    \"\"\"ZIPファイルを指定ディレクトリに解凍する\"\"\"\n",
                "    print(f\"Extracting {zip_path} to {extract_to}...\")\n",
                "    if extract_to.exists():\n",
                "        shutil.rmtree(extract_to)\n",
                "    extract_to.mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    subprocess.run(['unzip', '-q', str(zip_path), '-d', str(extract_to)], check=True)\n",
                "    print(\"Extraction complete.\")\n",
                "\n",
                "def create_batch_metadata(main_metadata_path, current_wav_dir, output_jsonl_path):\n",
                "    \"\"\"\n",
                "    メインのmetadata.jsonlから、現在解凍されているファイルに対応するエントリのみを抽出し、\n",
                "    パスをColab上の絶対パスに書き換えて新しいjsonlを作成する。\n",
                "    \"\"\"\n",
                "    print(f\"Creating batch metadata at {output_jsonl_path}...\")\n",
                "    \n",
                "    extracted_files = list(current_wav_dir.rglob('*.wav'))\n",
                "    extracted_files_map = {f.name: f for f in extracted_files}\n",
                "    \n",
                "    valid_entries = []\n",
                "    \n",
                "    with open(main_metadata_path, 'r', encoding='utf-8') as f:\n",
                "        for line in f:\n",
                "            try:\n",
                "                entry = json.loads(line)\n",
                "                orig_path = entry.get('path', '')\n",
                "                filename = os.path.basename(orig_path)\n",
                "                \n",
                "                if filename in extracted_files_map:\n",
                "                    # パスを絶対パスに更新\n",
                "                    entry['path'] = str(extracted_files_map[filename])\n",
                "                    # TransformersのDatasetで読み込むために 'audio' キーにパスを入れるのが一般的だが\n",
                "                    # ここでは後処理でロードするため 'path' のままでもOK。\n",
                "                    # ただし、datasets libraryのAudio機能を使うなら 'audio': path が便利。\n",
                "                    entry['audio'] = str(extracted_files_map[filename])\n",
                "                    valid_entries.append(entry)\n",
                "            except json.JSONDecodeError:\n",
                "                continue\n",
                "                \n",
                "    if not valid_entries:\n",
                "        print(\"Warning: No matching metadata found for extracted files.\")\n",
                "        return False\n",
                "        \n",
                "    with open(output_jsonl_path, 'w', encoding='utf-8') as f:\n",
                "        for entry in valid_entries:\n",
                "            f.write(json.dumps(entry) + '\\n')\n",
                "            \n",
                "    print(f\"Created metadata with {len(valid_entries)} entries.\")\n",
                "    return True\n",
                "\n",
                "def preprocess_function(examples, processor, audio_column_name=\"audio\", text_column_name=\"caption\"):\n",
                "    \"\"\"データセットの前処理関数\"\"\"\n",
                "    audio_arrays = [x[\"array\"] for x in examples[audio_column_name]]\n",
                "    sampling_rate = examples[audio_column_name][0][\"sampling_rate\"]\n",
                "    \n",
                "    # テキストの処理\n",
                "    # metadataのキーが 'caption' か 'text' か 'description' か確認が必要。\n",
                "    # ここでは 'caption' または 'text' を探す。\n",
                "    texts = []\n",
                "    for i in range(len(audio_arrays)):\n",
                "        # 柔軟にキーを探す\n",
                "        text = examples.get(text_column_name, [\"\"] * len(audio_arrays))[i]\n",
                "        if not text and \"text\" in examples:\n",
                "            text = examples[\"text\"][i]\n",
                "        if not text and \"description\" in examples:\n",
                "            text = examples[\"description\"][i]\n",
                "        texts.append(text if text else \"\")\n",
                "\n",
                "    inputs = processor(\n",
                "        audio=audio_arrays,\n",
                "        sampling_rate=sampling_rate,\n",
                "        text=texts,\n",
                "        padding=True,\n",
                "        truncation=True,\n",
                "        max_length=256, # テキストの最大長\n",
                "        return_tensors=\"pt\",\n",
                "    )\n",
                "    return inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48d16fd8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 5. メインループ実行\n",
                "import torch\n",
                "from transformers import AutoProcessor, MusicgenForConditionalGeneration, Trainer, TrainingArguments\n",
                "from datasets import load_dataset, Audio\n",
                "\n",
                "# モデルとプロセッサの準備\n",
                "MODEL_ID = \"facebook/musicgen-large\"\n",
                "print(f\"Loading model: {MODEL_ID}...\")\n",
                "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
                "model = MusicgenForConditionalGeneration.from_pretrained(MODEL_ID)\n",
                "model.train()\n",
                "\n",
                "# ZIPファイルリスト取得\n",
                "zip_files = sorted(list(ZIP_DIR.glob('archive_batch_*.zip')))\n",
                "print(f\"Found {len(zip_files)} zip files.\")\n",
                "\n",
                "# 以前のチェックポイントがあればロード（簡易実装）\n",
                "latest_checkpoint_path = OUTPUT_DIR / 'latest_checkpoint'\n",
                "if latest_checkpoint_path.exists():\n",
                "    print(f\"Resuming from {latest_checkpoint_path}...\")\n",
                "    model = MusicgenForConditionalGeneration.from_pretrained(latest_checkpoint_path)\n",
                "\n",
                "# GPU設定\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "model.to(device)\n",
                "\n",
                "for i, zip_file in enumerate(zip_files):\n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\"Processing Batch {i+1}/{len(zip_files)}: {zip_file.name}\")\n",
                "    print(f\"{'='*40}\")\n",
                "    \n",
                "    # 1. 解凍\n",
                "    extract_zip(zip_file, TEMP_DATA_DIR)\n",
                "    \n",
                "    # 2. メタデータ作成\n",
                "    batch_metadata_path = TEMP_WORK_DIR / 'batch.jsonl'\n",
                "    success = create_batch_metadata(METADATA_PATH, TEMP_DATA_DIR, batch_metadata_path)\n",
                "    \n",
                "    if not success:\n",
                "        print(\"Skipping this batch due to metadata error.\")\n",
                "        continue\n",
                "        \n",
                "    # 3. データセット準備\n",
                "    dataset = load_dataset(\"json\", data_files=str(batch_metadata_path), split=\"train\")\n",
                "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=processor.feature_extractor.sampling_rate))\n",
                "    \n",
                "    # 前処理の適用\n",
                "    print(\"Preprocessing dataset...\")\n",
                "    encoded_dataset = dataset.map(\n",
                "        lambda x: preprocess_function(x, processor),\n",
                "        batched=True,\n",
                "        remove_columns=dataset.column_names,\n",
                "        batch_size=4 # メモリに応じて調整\n",
                "    )\n",
                "    \n",
                "    # 4. トレーニング設定\n",
                "    # バッチごとにTrainerを作り直すが、modelは同じオブジェクトを使い回すことで学習を継続する\n",
                "    training_args = TrainingArguments(\n",
                "        output_dir=str(TEMP_WORK_DIR / \"results\"),\n",
                "        per_device_train_batch_size=2, # A100ならもう少し増やせるかも\n",
                "        gradient_accumulation_steps=4,\n",
                "        learning_rate=1e-5,\n",
                "        num_train_epochs=5, # 1バッチあたりのエポック数\n",
                "        save_steps=1000, # バッチ内での保存頻度（必要なら）\n",
                "        logging_steps=10,\n",
                "        fp16=True, # A100/V100ならTrue推奨\n",
                "        save_total_limit=1,\n",
                "        remove_unused_columns=False,\n",
                "        dataloader_num_workers=2,\n",
                "    )\n",
                "    \n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        train_dataset=encoded_dataset,\n",
                "    )\n",
                "    \n",
                "    print(\"Starting training for this batch...\")\n",
                "    trainer.train()\n",
                "    \n",
                "    # 5. モデル保存\n",
                "    # バッチ完了ごとにDriveへ保存\n",
                "    save_path = OUTPUT_DIR / f'checkpoint_batch_{i+1}'\n",
                "    print(f\"Saving model to {save_path}...\")\n",
                "    model.save_pretrained(save_path)\n",
                "    processor.save_pretrained(save_path)\n",
                "    \n",
                "    # 最新版として上書き\n",
                "    latest_path = OUTPUT_DIR / 'latest_checkpoint'\n",
                "    model.save_pretrained(latest_path)\n",
                "    processor.save_pretrained(latest_path)\n",
                "    \n",
                "    # 6. クリーンアップ\n",
                "    print(\"Cleaning up temp data...\")\n",
                "    shutil.rmtree(TEMP_DATA_DIR)\n",
                "    TEMP_DATA_DIR.mkdir(exist_ok=True)\n",
                "    # Trainerのクリーンアップ（メモリ解放のため）\n",
                "    del trainer\n",
                "    del dataset\n",
                "    del encoded_dataset\n",
                "    torch.cuda.empty_cache()\n",
                "\n",
                "print(\"All batches processed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}