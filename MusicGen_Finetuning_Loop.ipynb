{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MusicGen-Large Finetuning Loop (Sequential Processing)\n",
                "\n",
                "このノートブックは、大規模なデータセットをZIPファイル単位で順次処理（解凍→学習→削除）しながらMusicGen-Largeをファインチューニングします。\n",
                "Google Colabのディスク容量制限を回避するための設計です。\n",
                "\n",
                "## 前提条件\n",
                "1. Google Driveに以下のデータがあること\n",
                "   - `MyData/Archive_wavs/metadata.jsonl`: 全データのメタデータ\n",
                "   - `MyData/Archive_wavs/archive_batch_xxxx.zip`: 音声データのZIPファイル群\n",
                "2. A100 GPU推奨（VRAM容量のため）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. 環境設定とライブラリインストール\n",
                "!pip install -U git+https://github.com/facebookresearch/audiocraft.git\n",
                "!pip install -U xformers --index-url https://download.pytorch.org/whl/cu121\n",
                "# その他必要なライブラリ\n",
                "!pip install -U torch torchaudio"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Google Drive マウント\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. パスと設定の定義\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# --- ユーザー設定エリア ---\n",
                "DRIVE_ROOT = Path('/content/drive/MyDrive')\n",
                "DATA_ROOT = DRIVE_ROOT / 'MyData/Archive_wavs'\n",
                "METADATA_PATH = DATA_ROOT / 'metadata.jsonl'\n",
                "ZIP_DIR = DATA_ROOT\n",
                "\n",
                "# 出力先（チェックポイント保存場所）\n",
                "OUTPUT_DIR = DRIVE_ROOT / 'MusicGen_Finetuning_Output'\n",
                "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "# 一時作業ディレクトリ（Colabローカル）\n",
                "TEMP_WORK_DIR = Path('/content/temp_work')\n",
                "TEMP_DATA_DIR = TEMP_WORK_DIR / 'data'\n",
                "TEMP_CONFIG_DIR = TEMP_WORK_DIR / 'config'\n",
                "\n",
                "TEMP_DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
                "TEMP_CONFIG_DIR.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "print(f\"Metadata: {METADATA_PATH}\")\n",
                "print(f\"Zip Dir: {ZIP_DIR}\")\n",
                "print(f\"Output Dir: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. ヘルパー関数の定義\n",
                "import json\n",
                "import shutil\n",
                "import subprocess\n",
                "import glob\n",
                "\n",
                "def extract_zip(zip_path, extract_to):\n",
                "    \"\"\"ZIPファイルを指定ディレクトリに解凍する\"\"\"\n",
                "    print(f\"Extracting {zip_path} to {extract_to}...\")\n",
                "    # 既存データがあれば削除（クリーンな状態にする）\n",
                "    if extract_to.exists():\n",
                "        shutil.rmtree(extract_to)\n",
                "    extract_to.mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    subprocess.run(['unzip', '-q', str(zip_path), '-d', str(extract_to)], check=True)\n",
                "    print(\"Extraction complete.\")\n",
                "\n",
                "def create_batch_metadata(main_metadata_path, current_wav_dir, output_jsonl_path):\n",
                "    \"\"\"\n",
                "    メインのmetadata.jsonlから、現在解凍されているファイルに対応するエントリのみを抽出し、\n",
                "    パスをColab上の絶対パスに書き換えて新しいjsonlを作成する。\n",
                "    \"\"\"\n",
                "    print(f\"Creating batch metadata at {output_jsonl_path}...\")\n",
                "    \n",
                "    # 現在のディレクトリにあるWAVファイルのリストを取得（相対パス比較用）\n",
                "    # ZIP内の構造に依存するが、ここではファイル名または相対パスでマッチングを試みる\n",
                "    # metadataのpathが 'folder/file.wav' のような形式と仮定\n",
                "    \n",
                "    # まず、解凍された全ファイルの絶対パスを取得\n",
                "    extracted_files = list(current_wav_dir.rglob('*.wav'))\n",
                "    extracted_files_map = {f.name: f for f in extracted_files}\n",
                "    \n",
                "    valid_entries = []\n",
                "    \n",
                "    with open(main_metadata_path, 'r', encoding='utf-8') as f:\n",
                "        for line in f:\n",
                "            try:\n",
                "                entry = json.loads(line)\n",
                "                orig_path = entry.get('path', '')\n",
                "                filename = os.path.basename(orig_path)\n",
                "                \n",
                "                # ファイル名が一致するものが解凍先にあるか確認\n",
                "                if filename in extracted_files_map:\n",
                "                    # パスを絶対パスに更新\n",
                "                    entry['path'] = str(extracted_files_map[filename])\n",
                "                    valid_entries.append(entry)\n",
                "            except json.JSONDecodeError:\n",
                "                continue\n",
                "                \n",
                "    if not valid_entries:\n",
                "        print(\"Warning: No matching metadata found for extracted files.\")\n",
                "        return False\n",
                "        \n",
                "    with open(output_jsonl_path, 'w', encoding='utf-8') as f:\n",
                "        for entry in valid_entries:\n",
                "            f.write(json.dumps(entry) + '\\n')\n",
                "            \n",
                "    print(f\"Created metadata with {len(valid_entries)} entries.\")\n",
                "    return True\n",
                "\n",
                "def generate_config(batch_metadata_path, output_config_path, continue_from=None):\n",
                "    \"\"\"Audiocraft用の設定ファイル(yaml)を生成する\"\"\"\n",
                "    \n",
                "    # 基本設定\n",
                "    config_content = f\"\"\"\n",
                "# @package __global__\n",
                "\n",
                "defaults:\n",
                "  - musicgen/default\n",
                "  - _self_\n",
                "\n",
                "autocast: true\n",
                "compression_model_checkpoint: facebook/encodec_32khz\n",
                "channels: 1\n",
                "sample_rate: 32000\n",
                "\n",
                "deadlock_detection:\n",
                "  use: true\n",
                "\n",
                "dataset:\n",
                "  batch_size: 4  # GPUメモリに合わせて調整\n",
                "  num_workers: 4\n",
                "  segment_duration: 30\n",
                "  train:\n",
                "    path: {batch_metadata_path}\n",
                "  valid:\n",
                "    path: {batch_metadata_path} # 検証用も同じにしておく（または別途用意）\n",
                "  evaluate:\n",
                "    path: {batch_metadata_path}\n",
                "  generate:\n",
                "    path: {batch_metadata_path}\n",
                "\n",
                "checkpoint:\n",
                "  save_last: true\n",
                "  save_every: 10\n",
                "  keep_last: 5\n",
                "\n",
                "solver:\n",
                "  max_epochs: 5 # 1バッチあたりのエポック数\n",
                "  max_gen_epochs: 0\n",
                "  audio_generation: false\n",
                "\"\"\"\n",
                "\n",
                "    if continue_from:\n",
                "        config_content += f\"\\ncontinue_from: {continue_from}\\n\"\n",
                "\n",
                "    with open(output_config_path, 'w') as f:\n",
                "        f.write(config_content)\n",
                "    print(f\"Config generated at {output_config_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 5. メインループ実行\n",
                "import glob\n",
                "\n",
                "# ZIPファイルリスト取得\n",
                "zip_files = sorted(list(ZIP_DIR.glob('archive_batch_*.zip')))\n",
                "print(f\"Found {len(zip_files)} zip files.\")\n",
                "\n",
                "# チェックポイント管理\n",
                "latest_checkpoint = None\n",
                "# もし以前の学習済みモデルがあればそれを指定することも可能\n",
                "# latest_checkpoint = OUTPUT_DIR / 'checkpoint.th'\n",
                "\n",
                "for i, zip_file in enumerate(zip_files):\n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\"Processing Batch {i+1}/{len(zip_files)}: {zip_file.name}\")\n",
                "    print(f\"{'='*40}\")\n",
                "    \n",
                "    # 1. 解凍\n",
                "    extract_zip(zip_file, TEMP_DATA_DIR)\n",
                "    \n",
                "    # 2. メタデータ作成\n",
                "    batch_metadata_path = TEMP_WORK_DIR / 'batch.jsonl'\n",
                "    success = create_batch_metadata(METADATA_PATH, TEMP_DATA_DIR, batch_metadata_path)\n",
                "    \n",
                "    if not success:\n",
                "        print(\"Skipping this batch due to metadata error.\")\n",
                "        continue\n",
                "        \n",
                "    # 3. 設定ファイル生成\n",
                "    config_path = TEMP_CONFIG_DIR / 'solver.yaml'\n",
                "    generate_config(batch_metadata_path, config_path, continue_from=latest_checkpoint)\n",
                "    \n",
                "    # 4. 学習実行 (dora run)\n",
                "    # Audiocraftのsolverをサブプロセスで実行\n",
                "    # 注意: doraは通常コマンドラインツールだが、ここではpython -m audiocraft.solve で実行\n",
                "    # 設定ファイルは引数で渡す必要があるが、audiocraftはhydraを使っているため、\n",
                "    # 設定ディレクトリと設定名を指定する。\n",
                "    \n",
                "    # Hydraの仕様に合わせて引数を構築\n",
                "    # --config-path と --config-name を使う\n",
                "    cmd = [\n",
                "        'python', '-m', 'audiocraft.solve',\n",
                "        '--config-path', str(TEMP_CONFIG_DIR),\n",
                "        '--config-name', 'solver',\n",
                "        f'model=large', # MusicGen Large\n",
                "    ]\n",
                "    \n",
                "    print(\"Starting training...\")\n",
                "    try:\n",
                "        subprocess.run(cmd, check=True)\n",
                "        print(\"Training finished for this batch.\")\n",
                "    except subprocess.CalledProcessError as e:\n",
                "        print(f\"Training failed for {zip_file.name}: {e}\")\n",
                "        # エラーでも中断せず次へ行くか、ここで止めるかは要件次第。ここでは止める。\n",
                "        break\n",
                "        \n",
                "    # 5. モデル保存\n",
                "    # Audiocraftはデフォルトで ./checkpoints/ などに保存する。\n",
                "    # 最新のチェックポイントを探してDriveにコピーする。\n",
                "    # Hydraの出力ディレクトリは通常 ./outputs/日付/時間/...\n",
                "    # ここでは最新の outputs フォルダを探す\n",
                "    \n",
                "    # NOTE: 実際にはHydraのrun dirを固定するか、ログから取得するのが確実だが、\n",
                "    # 簡易的に最新の更新フォルダを探す。\n",
                "    try:\n",
                "        # カレントディレクトリ下のoutputsを探す\n",
                "        list_of_dirs = glob.glob('./outputs/*/*') # outputs/date/time\n",
                "        if list_of_dirs:\n",
                "            latest_dir = max(list_of_dirs, key=os.path.getctime)\n",
                "            ckpt_path = Path(latest_dir) / 'checkpoint.th'\n",
                "            \n",
                "            if ckpt_path.exists():\n",
                "                dest_path = OUTPUT_DIR / f'checkpoint_batch_{i+1}.th'\n",
                "                shutil.copy(ckpt_path, dest_path)\n",
                "                print(f\"Saved checkpoint to {dest_path}\")\n",
                "                \n",
                "                # 次のバッチのために最新チェックポイントパスを更新\n",
                "                latest_checkpoint = dest_path\n",
                "                \n",
                "                # 最新版として上書きもしておく\n",
                "                shutil.copy(ckpt_path, OUTPUT_DIR / 'latest_checkpoint.th')\n",
                "            else:\n",
                "                print(\"Checkpoint file not found in output dir.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error saving checkpoint: {e}\")\n",
                "        \n",
                "    # 6. クリーンアップ\n",
                "    print(\"Cleaning up temp data...\")\n",
                "    shutil.rmtree(TEMP_DATA_DIR)\n",
                "    TEMP_DATA_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(\"All batches processed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}