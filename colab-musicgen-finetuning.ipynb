{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c918ce9",
      "metadata": {
        "id": "5c918ce9"
      },
      "source": [
        "# MusicGen-Large LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (A100æŽ¨å¥¨)\n",
        "\n",
        "**ç›®çš„**: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç´„18,000æ›²ï¼‰ã‚’ä½¿ã„ã€MusicGen-Large ã« LoRA ã‚’é©ç”¨ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚\n",
        "Google Colabã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡åˆ¶é™ã‚’å›žé¿ã™ã‚‹ãŸã‚ã€**é †æ¬¡å‡¦ç†æˆ¦ç•¥ï¼ˆæŠ½å‡ºâ†’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–â†’å‰Šé™¤ï¼‰**ã‚’æŽ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“‹ äº‹å‰æº–å‚™\n",
        "\n",
        "1. **Google Colabã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ **: GPU (A100æŽ¨å¥¨) ã‚’é¸æŠž\n",
        "2. **ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®è¨­å®š**: Colabã®ã€ŒðŸ”‘ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ä»¥ä¸‹ã‚’è¨­å®š\n",
        "   - `WANDB_API_KEY`: WandB APIã‚­ãƒ¼\n",
        "   - `HF_TOKEN`: Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "3. **Google Drive**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ`archive_batch_xxxx.zip` å½¢å¼ï¼‰ã‚’é…ç½®\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš€ ä½¿ã„æ–¹\n",
        "\n",
        "1. ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ\n",
        "2. ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰è‡ªå‹•çš„ã«APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "3. WandBã§å­¦ç¿’é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–: https://wandb.ai/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff6e8f3d",
      "metadata": {
        "id": "ff6e8f3d"
      },
      "source": [
        "# ã‚»ãƒ« 1 â€” ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e81e6e23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e81e6e23",
        "outputId": "818530c6-bdcb-4c38-a4f8-bc2a16be543a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.3.0+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.3.0%2Bcu118-cp312-cp312-linux_x86_64.whl (839.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m839.6/839.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.3.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m138.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.7.0.84 (from torch==2.3.0+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nccl-cu11==2.20.5 (from torch==2.3.0+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m171.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.3.0+cu118)\n",
            "  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu118) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu118) (1.3.0)\n",
            "Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchaudio\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.9.0+cu126\n",
            "\u001b[2K    Uninstalling torch-2.9.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torch-2.9.0+cu126\n",
            "\u001b[2K  Attempting uninstall: torchaudio\n",
            "\u001b[2K    Found existing installation: torchaudio 2.9.0+cu126\n",
            "\u001b[2K    Uninstalling torchaudio-2.9.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/13\u001b[0m [torchaudio]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.3.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.3.0+cu118 torchaudio-2.3.0+cu118\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,153 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,491 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
            "Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,836 kB]\n",
            "Fetched 37.5 MB in 4s (9,191 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Collecting encodec\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from encodec) (2.3.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from encodec) (2.3.0+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from encodec) (0.8.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->encodec) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->encodec) (1.3.0)\n",
            "Building wheels for collected packages: encodec\n",
            "  Building wheel for encodec (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45853 sha256=8a6f92b83b2f78ba36c71b6e46ddfa0da20d963f1f278ed088c2284d4c4be4d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/eb/9f/e13610cc46ab39d3199fbabebd1c3e142d44b679526e0f228a\n",
            "Successfully built encodec\n",
            "Installing collected packages: encodec\n",
            "Successfully installed encodec-0.1.1\n",
            "Collecting git+https://github.com/facebookresearch/audiocraft.git@main\n",
            "  Cloning https://github.com/facebookresearch/audiocraft.git (to revision main) to /tmp/pip-req-build-ns5lorms\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/audiocraft.git /tmp/pip-req-build-ns5lorms\n",
            "  Resolved https://github.com/facebookresearch/audiocraft.git to commit 896ec7c47f5e5d1e5aa1e4b260c4405328bf009d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av==11.0.0 (from audiocraft==1.4.0a2)\n",
            "  Downloading av-11.0.0.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'av' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting deepspeed\n",
            "  Downloading deepspeed-0.18.2.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Collecting loralib\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed) (0.8.1)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.1.2)\n",
            "Collecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.12.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.3.0+cu118)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->deepspeed) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.18.2-py3-none-any.whl size=1763315 sha256=58e9f6b0379bf99f43daba1477705b3462921bfa49ef7b8b01334290be1a7418\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/ad/2e/e03d4739ddc0417efd8a120c2b9e784005aa226037e558c163\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: hjson, ninja, loralib, deepspeed\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [deepspeed]\n",
            "\u001b[1A\u001b[2KSuccessfully installed deepspeed-0.18.2 hjson-3.1.0 loralib-0.1.2 ninja-1.13.0\n",
            "ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
          ]
        }
      ],
      "source": [
        "# å®Ÿè¡Œå‰ã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã® GPU ã‚’ç¢ºèªã€‚CUDA ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã‚ã›ã¦ torch ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚\n",
        "# Colabã®ç’°å¢ƒã«åˆã‚ã›ã¦ã€åˆ©ç”¨å¯èƒ½ãªæœ€æ–°ã®cu118å¯¾å¿œPyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°ã€‚\n",
        "# ä¾‹ï¼šCUDA 11.8 / PyTorch 2.3 ã®å ´åˆ\n",
        "!pip install --upgrade pip\n",
        "!pip install torch==2.3.0+cu118 torchaudio==2.3.0 --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# audiocraft ã®ä¾å­˜é–¢ä¿‚ã‚’å…ˆã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ç«¶åˆã‚’å›žé¿\n",
        "!pip install soundfile librosa encodec\n",
        "\n",
        "# audiocraft (MusicGen ã‚’å«ã‚€) å…¬å¼ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰\n",
        "!pip install -U git+https://github.com/facebookresearch/audiocraft.git@main\n",
        "\n",
        "# LoRA / DeepSpeed / WandB ãªã©\n",
        "!pip install deepspeed wandb loralib tqdm\n",
        "\n",
        "print(\"ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d6290e",
      "metadata": {
        "id": "11d6290e"
      },
      "source": [
        "# ã‚»ãƒ« 2 â€” Drive ãƒžã‚¦ãƒ³ãƒˆã¨è¨­å®š\n",
        "\n",
        "Google Driveã‚’ãƒžã‚¦ãƒ³ãƒˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "53bd8d67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53bd8d67",
        "outputId": "7a818eed-dbf5-4989-cfe7-e8a498373690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ZIPæ ¼ç´å ´æ‰€: /content/drive/MyDrive/Archive_wavs\n",
            "ä¸€æ™‚å±•é–‹å…ˆ: /content/temp_dataset\n",
            "ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜å…ˆ: /content/drive/MyDrive/MusicGen_Tokens\n",
            "æ¤œå‡ºã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«æ•°: 0\n",
            "âš ï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# è¨­å®š\n",
        "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "DRIVE_ARCHIVE_DIR = '/content/drive/MyDrive/Archive_Wavs'\n",
        "\n",
        "# ä¸€æ™‚å±•é–‹å…ˆï¼ˆColabãƒ­ãƒ¼ã‚«ãƒ«ï¼‰\n",
        "TEMP_DATA_DIR = '/content/temp_dataset'\n",
        "\n",
        "# ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜å…ˆï¼ˆGoogle DriveæŽ¨å¥¨ã€ã¾ãŸã¯å®¹é‡ãŒã‚ã‚Œã°ãƒ­ãƒ¼ã‚«ãƒ«ï¼‰\n",
        "# â€»å†é–‹å¯èƒ½ã«ã™ã‚‹ãŸã‚DriveæŽ¨å¥¨ã§ã™ãŒã€I/OãŒé…ã„å ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ã«ã—ã¦æœ€å¾Œã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹æˆ¦ç•¥ã‚‚å¯\n",
        "# ã“ã“ã§ã¯Driveã«ç›´æŽ¥ä¿å­˜ã™ã‚‹è¨­å®šã«ã—ã¾ã™\n",
        "TOKEN_DIR = '/content/drive/MyDrive/MusicGen_Tokens'\n",
        "\n",
        "os.makedirs(TOKEN_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(f'ZIPæ ¼ç´å ´æ‰€: {DRIVE_ARCHIVE_DIR}')\n",
        "print(f'ä¸€æ™‚å±•é–‹å…ˆ: {TEMP_DATA_DIR}')\n",
        "print(f'ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜å…ˆ: {TOKEN_DIR}')\n",
        "\n",
        "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
        "zip_files = sorted(list(Path(DRIVE_ARCHIVE_DIR).glob('archive_batch_*.zip')))\n",
        "print(f'æ¤œå‡ºã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(zip_files)}')\n",
        "if len(zip_files) > 0:\n",
        "    print(f'ä¾‹: {zip_files[0].name}')\n",
        "else:\n",
        "    print('âš ï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b1cecb",
      "metadata": {
        "id": "d8b1cecb"
      },
      "source": [
        "# ã‚»ãƒ« 2.5 â€” WandBã¨Hugging Faceã®èªè¨¼è¨­å®š\n",
        "\n",
        "ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0df137c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0df137c8",
        "outputId": "f1c3c364-523d-4fc5-f26d-e537b01ca20d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ èªè¨¼ã‚¨ãƒ©ãƒ¼: Requesting secret WANDB_API_KEY timed out. Secrets can only be fetched when running from the Colab UI.\n",
            "Colabã®ã€Œã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:\n",
            "  - WANDB_API_KEY: WandBã®APIã‚­ãƒ¼\n",
            "  - HF_TOKEN: Hugging Faceã®APIãƒˆãƒ¼ã‚¯ãƒ³\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "try:\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "    # WandBãƒ­ã‚°ã‚¤ãƒ³\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "    print(\"âœ“ WandBã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ\")\n",
        "\n",
        "    # Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®š\n",
        "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "    print(\"âœ“ Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ã¾ã—ãŸ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "    print(\"Colabã®ã€Œã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:\")\n",
        "    print(\"  - WANDB_API_KEY: WandBã®APIã‚­ãƒ¼\")\n",
        "    print(\"  - HF_TOKEN: Hugging Faceã®APIãƒˆãƒ¼ã‚¯ãƒ³\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e6e1451",
      "metadata": {
        "id": "1e6e1451"
      },
      "source": [
        "# ã‚»ãƒ« 2.6 â€” ðŸ§ª å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ\n",
        "\n",
        "æœ€åˆã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å°‘æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡ºã—ã¦ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®å‹•ä½œç¢ºèªã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3cdaf43",
      "metadata": {
        "id": "a3cdaf43"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchaudio\n",
        "from audiocraft.models import CompressionModel, MusicGen\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import loralib as lora\n",
        "import torch.nn as nn\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆè¨­å®š\n",
        "TEST_MODE = True\n",
        "NUM_TEST_SAMPLES = 5\n",
        "TEST_EPOCHS = 2\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ðŸ§ª å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "TEST_DIR = '/content/test_workspace'\n",
        "TEST_WAV_DIR = os.path.join(TEST_DIR, 'wavs')\n",
        "TEST_TOKEN_DIR = os.path.join(TEST_DIR, 'tokens')\n",
        "os.makedirs(TEST_WAV_DIR, exist_ok=True)\n",
        "os.makedirs(TEST_TOKEN_DIR, exist_ok=True)\n",
        "\n",
        "# 1. ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºï¼ˆæœ€åˆã®ZIPã‹ã‚‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ï¼‰\n",
        "print(\"ðŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\")\n",
        "if len(zip_files) > 0:\n",
        "    target_zip = zip_files[0]\n",
        "    print(f\"  ZIPãƒ•ã‚¡ã‚¤ãƒ«: {target_zip.name}\")\n",
        "    # ä¸€æ™‚çš„ã«å±•é–‹ã—ã¦æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã‚³ãƒ”ãƒ¼\n",
        "    !mkdir -p /content/temp_extract\n",
        "    !tar -xzf \"{target_zip}\" -C /content/temp_extract\n",
        "\n",
        "    extracted_files = list(Path('/content/temp_extract').rglob('*.wav'))\n",
        "    print(f\"  æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(extracted_files)}\")\n",
        "\n",
        "    for i, f in enumerate(extracted_files[:NUM_TEST_SAMPLES]):\n",
        "        shutil.copy(f, TEST_WAV_DIR)\n",
        "        print(f\"  ã‚³ãƒ”ãƒ¼: {f.name}\")\n",
        "\n",
        "    # æŽƒé™¤\n",
        "    !rm -rf /content/temp_extract\n",
        "else:\n",
        "    print(\"âš ï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™\")\n",
        "    # ãƒ€ãƒŸãƒ¼WAVä½œæˆï¼ˆæ­£å¼¦æ³¢ï¼‰\n",
        "    sr = 32000\n",
        "    for i in range(NUM_TEST_SAMPLES):\n",
        "        t = torch.linspace(0, 5, sr * 5)\n",
        "        wav = torch.sin(2 * 3.14159 * 440 * t).unsqueeze(0)\n",
        "        torchaudio.save(os.path.join(TEST_WAV_DIR, f'test_{i}.wav'), wav, sr)\n",
        "\n",
        "test_paths = list(Path(TEST_WAV_DIR).glob('*.wav'))\n",
        "print(f\"âœ“ {len(test_paths)}å€‹ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„\")\n",
        "print()\n",
        "\n",
        "# 2. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ðŸŽµ ã‚¹ãƒ†ãƒƒãƒ—2: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ\")\n",
        "compression_model = CompressionModel.get_pretrained('facebook/encodec_32khz')\n",
        "compression_model.to('cuda')\n",
        "compression_model.eval()\n",
        "\n",
        "for i, p in enumerate(test_paths):\n",
        "    try:\n",
        "        wav, sr = torchaudio.load(p)\n",
        "        if sr != 32000:\n",
        "            resampler = torchaudio.transforms.Resample(sr, 32000)\n",
        "            wav = resampler(wav)\n",
        "        if wav.shape[0] > 1:\n",
        "            wav = wav.mean(dim=0, keepdim=True)\n",
        "        wav = wav.unsqueeze(0).to('cuda')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            encoded_frames = compression_model.encode(wav)\n",
        "            tokens = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)\n",
        "\n",
        "        outp = os.path.join(TEST_TOKEN_DIR, p.stem + '.pt')\n",
        "        torch.save({'tokens': tokens.cpu(), 'path': str(p)}, outp)\n",
        "        print(f\"  âœ“ ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å®Œäº†: {p.name} -> {tokens.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âœ— ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "\n",
        "del compression_model\n",
        "torch.cuda.empty_cache()\n",
        "print()\n",
        "\n",
        "# 3. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ðŸ“¦ ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "class TestTokenDataset(Dataset):\n",
        "    def __init__(self, token_dir, max_length=1500):\n",
        "        self.files = sorted(list(Path(token_dir).glob('*.pt')))\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.load(self.files[idx])\n",
        "        tokens = data['tokens']\n",
        "        if tokens.dim() == 3: tokens = tokens.squeeze(0)\n",
        "        seq_len = tokens.shape[-1]\n",
        "        if seq_len > self.max_length:\n",
        "            tokens = tokens[:, :self.max_length]\n",
        "        elif seq_len < self.max_length:\n",
        "            pad = self.max_length - seq_len\n",
        "            tokens = torch.nn.functional.pad(tokens, (0, pad), value=0)\n",
        "        return tokens\n",
        "\n",
        "test_dataset = TestTokenDataset(TEST_TOKEN_DIR)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
        "for batch in test_loader:\n",
        "    print(f\"âœ“ ãƒãƒƒãƒå½¢çŠ¶: {batch.shape}\")\n",
        "    break\n",
        "print()\n",
        "\n",
        "# 4. ãƒ¢ãƒ‡ãƒ«ã¨LoRAã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ðŸ¤– ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¨LoRAé©ç”¨ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "model.to('cuda')\n",
        "model.eval()\n",
        "\n",
        "def apply_lora_to_linear(module, r=8, lora_alpha=32, lora_dropout=0.1, parent_name='', count=[0]):\n",
        "    for name, child in list(module.named_children()):\n",
        "        if isinstance(child, nn.Linear) and count[0] < 3:  # ãƒ†ã‚¹ãƒˆç”¨åˆ¶é™\n",
        "            lora_linear = lora.Linear(child.in_features, child.out_features, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, bias=(child.bias is not None))\n",
        "            lora_linear.weight.data = child.weight.data.clone()\n",
        "            if child.bias is not None: lora_linear.bias.data = child.bias.data.clone()\n",
        "            setattr(module, name, lora_linear)\n",
        "            count[0] += 1\n",
        "            print(f\"  âœ“ LoRAé©ç”¨: {parent_name}.{name}\")\n",
        "        else:\n",
        "            apply_lora_to_linear(child, r, lora_alpha, lora_dropout, f\"{parent_name}.{name}\" if parent_name else name, count)\n",
        "\n",
        "apply_lora_to_linear(model.lm, r=8)\n",
        "print(\"âœ“ LoRAé©ç”¨å®Œäº†\")\n",
        "print()\n",
        "\n",
        "# 5. å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ðŸ‹ï¸ ã‚¹ãƒ†ãƒƒãƒ—5: å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "model.train()\n",
        "for epoch in range(TEST_EPOCHS):\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to('cuda')\n",
        "        out = model.lm.forward(batch)\n",
        "        loss = criterion(out, batch.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        print(f\"  Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "        break\n",
        "print()\n",
        "\n",
        "# 6. ç”Ÿæˆãƒ†ã‚¹ãƒˆ\n",
        "print(\"ðŸŽ¶ ã‚¹ãƒ†ãƒƒãƒ—6: ç”Ÿæˆãƒ†ã‚¹ãƒˆ\")\n",
        "model.eval()\n",
        "model.set_generation_params(duration=5)\n",
        "with torch.no_grad():\n",
        "    wav = model.generate([\"Test melody\"])\n",
        "print(f\"âœ“ ç”Ÿæˆå®Œäº†: {wav.shape}\")\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "print(\"âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88cf0992",
      "metadata": {
        "id": "88cf0992"
      },
      "source": [
        "# ã‚»ãƒ« 3 â€” é †æ¬¡å‡¦ç†ã«ã‚ˆã‚‹ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º (Sequential Tokenization)\n",
        "\n",
        "**æˆ¦ç•¥**: ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ãšã¤å±•é–‹ â†’ ãƒˆãƒ¼ã‚¯ãƒ³åŒ– â†’ WAVå‰Šé™¤ ã‚’ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚\n",
        "ã“ã‚Œã«ã‚ˆã‚Šã€Colabã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’åœ§è¿«ã›ãšã«å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã§ãã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de228b0",
      "metadata": {
        "id": "0de228b0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import shutil\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from audiocraft.models import CompressionModel\n",
        "import wandb\n",
        "\n",
        "# WandBåˆæœŸåŒ–\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    if not wandb.api.api_key: wandb.login(key=WANDB_API_KEY)\n",
        "    wandb.init(project='musicgen-lora-finetune', name='sequential_tokenization', job_type='preprocessing')\n",
        "    use_wandb = True\n",
        "except: use_wandb = False\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
        "print('EnCodecãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "compression_model = CompressionModel.get_pretrained('facebook/encodec_32khz')\n",
        "compression_model.to('cuda')\n",
        "compression_model.eval()\n",
        "\n",
        "# å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
        "existing_tokens = set([Path(f).stem for f in glob.glob(os.path.join(TOKEN_DIR, '*.pt'))])\n",
        "print(f'æ—¢ã«ãƒˆãƒ¼ã‚¯ãƒ³åŒ–æ¸ˆã¿: {len(existing_tokens)} ãƒ•ã‚¡ã‚¤ãƒ«')\n",
        "\n",
        "total_processed = 0\n",
        "start_time = time.time()\n",
        "\n",
        "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®ãƒ«ãƒ¼ãƒ—\n",
        "for zip_idx, zip_file in enumerate(tqdm(zip_files, desc='ZIPãƒãƒƒãƒå‡¦ç†')):\n",
        "    print(f'\\nðŸ“¦ å‡¦ç†ä¸­: {zip_file.name} ({zip_idx+1}/{len(zip_files)})')\n",
        "\n",
        "    # 1. å±•é–‹ (Extract)\n",
        "    if os.path.exists(TEMP_DATA_DIR):\n",
        "        shutil.rmtree(TEMP_DATA_DIR)\n",
        "    os.makedirs(TEMP_DATA_DIR, exist_ok=True)\n",
        "\n",
        "    print('  â†³ å±•é–‹ä¸­...')\n",
        "    !tar -xzf \"{zip_file}\" -C \"{TEMP_DATA_DIR}\"\n",
        "\n",
        "    wav_files = list(Path(TEMP_DATA_DIR).rglob('*.wav'))\n",
        "    print(f'  â†³ {len(wav_files)} å€‹ã®WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º')\n",
        "\n",
        "    # 2. ãƒˆãƒ¼ã‚¯ãƒ³åŒ– (Tokenize)\n",
        "    batch_processed = 0\n",
        "    for wav_path in tqdm(wav_files, desc='  â†³ ãƒˆãƒ¼ã‚¯ãƒ³åŒ–', leave=False):\n",
        "        if wav_path.stem in existing_tokens:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            wav, sr = torchaudio.load(str(wav_path))\n",
        "            if sr != 32000:\n",
        "                resampler = torchaudio.transforms.Resample(sr, 32000)\n",
        "                wav = resampler(wav)\n",
        "            if wav.shape[0] > 1:\n",
        "                wav = wav.mean(dim=0, keepdim=True)\n",
        "            wav = wav.unsqueeze(0).to('cuda')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                encoded_frames = compression_model.encode(wav)\n",
        "                tokens = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)\n",
        "\n",
        "            outp = os.path.join(TOKEN_DIR, wav_path.stem + '.pt')\n",
        "            torch.save({'tokens': tokens.cpu(), 'path': str(wav_path)}, outp)\n",
        "\n",
        "            batch_processed += 1\n",
        "            total_processed += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Error: {wav_path.name} - {e}')\n",
        "            continue\n",
        "\n",
        "    # 3. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— (Cleanup)\n",
        "    print('  â†³ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...')\n",
        "    shutil.rmtree(TEMP_DATA_DIR)\n",
        "\n",
        "    # ãƒ­ã‚°\n",
        "    if use_wandb:\n",
        "        wandb.log({\n",
        "            'processed_files': total_processed,\n",
        "            'processed_zips': zip_idx + 1,\n",
        "            'files_in_batch': batch_processed\n",
        "        })\n",
        "\n",
        "print(f'\\nâœ… å…¨å‡¦ç†å®Œäº†: {total_processed} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°è¦ã«ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¾ã—ãŸ')\n",
        "if use_wandb: wandb.finish()\n",
        "\n",
        "del compression_model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7a3f7af",
      "metadata": {
        "id": "f7a3f7af"
      },
      "source": [
        "# ã‚»ãƒ« 4 â€” DeepSpeed è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2b74acb",
      "metadata": {
        "id": "e2b74acb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "ds_config = {\n",
        "  \"train_batch_size\": 16,\n",
        "  \"train_micro_batch_size_per_gpu\": 2,\n",
        "  \"gradient_accumulation_steps\": 8,\n",
        "  \"optimizer\": {\n",
        "    \"type\": \"AdamW\",\n",
        "    \"params\": {\n",
        "      \"lr\": 1e-4,\n",
        "      \"weight_decay\": 0.01\n",
        "    }\n",
        "  },\n",
        "  \"fp16\": {\n",
        "    \"enabled\": True\n",
        "  },\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 3,\n",
        "    \"offload_optimizer\": {\n",
        "      \"device\": \"cpu\",\n",
        "      \"pin_memory\": True\n",
        "    },\n",
        "    \"offload_param\": {\n",
        "      \"device\": \"cpu\"\n",
        "    },\n",
        "    \"overlap_comm\": True,\n",
        "    \"contiguous_gradients\": True\n",
        "  }\n",
        "}\n",
        "\n",
        "with open('ds_config.json','w') as f:\n",
        "    json.dump(ds_config, f, indent=2)\n",
        "\n",
        "print('ds_config.json ã‚’ä½œæˆã—ã¾ã—ãŸ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2967cb7b",
      "metadata": {
        "id": "2967cb7b"
      },
      "source": [
        "# ã‚»ãƒ« 5 â€” ãƒ¢ãƒ‡ãƒ«æº–å‚™ã¨LoRAé©ç”¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0395dd07",
      "metadata": {
        "id": "0395dd07"
      },
      "outputs": [],
      "source": [
        "import loralib as lora\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from audiocraft.models import MusicGen\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
        "print('MusicGen-Large ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "model.eval()\n",
        "\n",
        "# LoRAé©ç”¨é–¢æ•°\n",
        "def apply_lora_to_linear(module, r=8, lora_alpha=32, lora_dropout=0.1, parent_name=''):\n",
        "    for name, child in list(module.named_children()):\n",
        "        full_name = f\"{parent_name}.{name}\" if parent_name else name\n",
        "        if isinstance(child, nn.Linear):\n",
        "            lora_linear = lora.Linear(\n",
        "                child.in_features, child.out_features, r=r,\n",
        "                lora_alpha=lora_alpha, lora_dropout=lora_dropout, bias=(child.bias is not None)\n",
        "            )\n",
        "            lora_linear.weight.data = child.weight.data.clone()\n",
        "            if child.bias is not None:\n",
        "                lora_linear.bias.data = child.bias.data.clone()\n",
        "            setattr(module, name, lora_linear)\n",
        "            print(f'Applied LoRA to: {full_name}')\n",
        "        else:\n",
        "            apply_lora_to_linear(child, r, lora_alpha, lora_dropout, full_name)\n",
        "\n",
        "print('\\nLoRAã‚’é©ç”¨ä¸­...')\n",
        "apply_lora_to_linear(model.lm, r=8)\n",
        "\n",
        "# å‹¾é…è¨­å®š\n",
        "for p in model.parameters(): p.requires_grad = False\n",
        "for name, p in model.named_parameters():\n",
        "    if 'lora_' in name: p.requires_grad = True\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f'\\nå­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41971f7b",
      "metadata": {
        "id": "41971f7b"
      },
      "source": [
        "# ã‚»ãƒ« 6 â€” ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ä½œæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba719a13",
      "metadata": {
        "id": "ba719a13"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "class TokenDataset(Dataset):\n",
        "    def __init__(self, token_dir, max_length=1500):\n",
        "        self.files = sorted(list(Path(token_dir).glob('*.pt')))\n",
        "        self.max_length = max_length\n",
        "        print(f'Dataset initialized with {len(self.files)} samples')\n",
        "\n",
        "    def __len__(self): return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.load(self.files[idx])\n",
        "        tokens = data['tokens']\n",
        "        if tokens.dim() == 3: tokens = tokens.squeeze(0)\n",
        "\n",
        "        seq_len = tokens.shape[-1]\n",
        "        if seq_len > self.max_length:\n",
        "            start = random.randint(0, seq_len - self.max_length)\n",
        "            tokens = tokens[:, start:start + self.max_length]\n",
        "        elif seq_len < self.max_length:\n",
        "            pad = self.max_length - seq_len\n",
        "            tokens = torch.nn.functional.pad(tokens, (0, pad), value=0)\n",
        "        return tokens\n",
        "\n",
        "dataset = TokenDataset(TOKEN_DIR, max_length=1500)\n",
        "train_size = int(0.95 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f'Train: {len(train_dataset)}, Valid: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da7a627b",
      "metadata": {
        "id": "da7a627b"
      },
      "source": [
        "# ã‚»ãƒ« 7 â€” å­¦ç¿’ãƒ«ãƒ¼ãƒ— (WandB + Checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47016277",
      "metadata": {
        "id": "47016277"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "# WandBåˆæœŸåŒ–\n",
        "try:\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    if not wandb.api.api_key: wandb.login(key=WANDB_API_KEY)\n",
        "    wandb.init(project='musicgen-lora-finetune', name='training_run', tags=['musicgen', 'lora', 'a100'])\n",
        "    use_wandb = True\n",
        "except: use_wandb = False\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=0.01)\n",
        "\n",
        "# ä¿å­˜å…ˆè¨­å®š\n",
        "CKPT_DIR = '/content/drive/MyDrive/MusicGen_Checkpoints'\n",
        "LORA_DIR = os.path.join(CKPT_DIR, 'lora_weights')\n",
        "FULL_MODEL_DIR = os.path.join(CKPT_DIR, 'full_models')\n",
        "os.makedirs(LORA_DIR, exist_ok=True)\n",
        "os.makedirs(FULL_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "def extract_lora_weights(model):\n",
        "    return {name: param.cpu().detach().clone() for name, param in model.named_parameters() if 'lora_' in name and param.requires_grad}\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, global_step, loss, checkpoint_type='regular'):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch, 'global_step': global_step, 'model_state': model.state_dict(),\n",
        "        'opt_state': optimizer.state_dict(), 'loss': loss, 'best_loss': best_loss,\n",
        "        'timestamp': time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    }\n",
        "    lora_checkpoint = {\n",
        "        'epoch': epoch, 'global_step': global_step, 'lora_weights': extract_lora_weights(model),\n",
        "        'loss': loss, 'timestamp': checkpoint['timestamp']\n",
        "    }\n",
        "\n",
        "    if checkpoint_type == 'regular':\n",
        "        torch.save(checkpoint, os.path.join(CKPT_DIR, 'latest.pt'))\n",
        "        torch.save(lora_checkpoint, os.path.join(LORA_DIR, 'latest_lora.pt'))\n",
        "    elif checkpoint_type == 'best':\n",
        "        torch.save(checkpoint, os.path.join(FULL_MODEL_DIR, 'best_model.pt'))\n",
        "        torch.save(lora_checkpoint, os.path.join(LORA_DIR, 'best_lora.pt'))\n",
        "        print(f'  ðŸ† ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜: Loss {loss:.4f}')\n",
        "    elif checkpoint_type == 'epoch':\n",
        "        torch.save(checkpoint, os.path.join(FULL_MODEL_DIR, f'checkpoint_epoch_{epoch+1}.pt'))\n",
        "        torch.save(lora_checkpoint, os.path.join(LORA_DIR, f'lora_epoch_{epoch+1}.pt'))\n",
        "    elif checkpoint_type == 'step':\n",
        "        torch.save(checkpoint, os.path.join(CKPT_DIR, f'checkpoint_step_{global_step}.pt'))\n",
        "\n",
        "# å†é–‹å‡¦ç†\n",
        "start_epoch = 0\n",
        "global_step = 0\n",
        "best_loss = float('inf')\n",
        "latest_ckpt = os.path.join(CKPT_DIR, 'latest.pt')\n",
        "if os.path.exists(latest_ckpt):\n",
        "    print(f'ðŸ”„ å†é–‹: {latest_ckpt}')\n",
        "    ckpt = torch.load(latest_ckpt, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model_state'], strict=False)\n",
        "    optimizer.load_state_dict(ckpt['opt_state'])\n",
        "    start_epoch = ckpt['epoch'] + 1\n",
        "    global_step = ckpt.get('global_step', 0)\n",
        "    best_loss = ckpt.get('best_loss', float('inf'))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "num_epochs = 5\n",
        "accum_steps = 8\n",
        "\n",
        "print('\\nðŸš€ å­¦ç¿’é–‹å§‹')\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "    for batch_idx, tokens in enumerate(pbar):\n",
        "        try:\n",
        "            tokens = tokens.to(device)\n",
        "            outputs = model.lm.forward(tokens)\n",
        "            loss = criterion(outputs, tokens.float()) / accum_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (batch_idx + 1) % accum_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if use_wandb and global_step % 10 == 0:\n",
        "                    wandb.log({'train/loss': loss.item() * accum_steps, 'train/step': global_step})\n",
        "                if global_step % 500 == 0:\n",
        "                    save_checkpoint(model, optimizer, epoch, global_step, loss.item() * accum_steps, 'step')\n",
        "\n",
        "            epoch_loss += loss.item() * accum_steps\n",
        "            pbar.set_postfix({'loss': f'{loss.item() * accum_steps:.4f}'})\n",
        "        except Exception as e:\n",
        "            print(f'Error: {e}')\n",
        "            continue\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f'\\nEpoch {epoch+1} Loss: {avg_loss:.4f}')\n",
        "\n",
        "    if use_wandb: wandb.log({'epoch/loss': avg_loss, 'epoch': epoch+1})\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        save_checkpoint(model, optimizer, epoch, global_step, avg_loss, 'best')\n",
        "\n",
        "    save_checkpoint(model, optimizer, epoch, global_step, avg_loss, 'regular')\n",
        "    save_checkpoint(model, optimizer, epoch, global_step, avg_loss, 'epoch')\n",
        "\n",
        "print('ðŸŽ‰ å­¦ç¿’å®Œäº†')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0353a749",
      "metadata": {
        "id": "0353a749"
      },
      "source": [
        "# ã‚»ãƒ« 8 â€” æ¥½æ›²ç”Ÿæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e68fad",
      "metadata": {
        "id": "68e68fad"
      },
      "outputs": [],
      "source": [
        "from audiocraft.data.audio import audio_write\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "print('ðŸŽµ æ¥½æ›²ç”Ÿæˆ')\n",
        "model.eval()\n",
        "model.set_generation_params(use_sampling=True, top_k=250, duration=30)\n",
        "\n",
        "prompts = [\n",
        "    \"A dynamic heavy metal song with fast drums and guitar solo\",\n",
        "    \"Relaxing jazz piano with soft background ambience\",\n",
        "    \"Upbeat electronic dance music with strong bass\"\n",
        "]\n",
        "\n",
        "with torch.no_grad():\n",
        "    wav = model.generate(prompts)\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/MusicGen_Generated'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for idx, one_wav in enumerate(wav):\n",
        "    filename = os.path.join(output_dir, f\"generated_{idx}\")\n",
        "    audio_write(filename, one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    print(f'\\nPrompt: {prompts[idx]}')\n",
        "    display(Audio(filename + \".wav\"))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}