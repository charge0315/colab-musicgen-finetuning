{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c918ce9",
      "metadata": {
        "id": "5c918ce9"
      },
      "source": [
        "# MusicGen-Large LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (A100æ¨å¥¨)\n",
        "\n",
        "**ç›®çš„**: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç´„18,000æ›²ï¼‰ã‚’ä½¿ã„ã€MusicGen-Large ã« LoRA ã‚’é©ç”¨ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚\n",
        "Google Colabã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡åˆ¶é™ã‚’å›é¿ã™ã‚‹ãŸã‚ã€**é †æ¬¡å‡¦ç†æˆ¦ç•¥ï¼ˆæŠ½å‡ºâ†’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–â†’å‰Šé™¤ï¼‰**ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ äº‹å‰æº–å‚™\n",
        "\n",
        "1. **Google Colabã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ **: GPU (A100æ¨å¥¨) ã‚’é¸æŠ\n",
        "2. **ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®è¨­å®š**: Colabã®ã€ŒğŸ”‘ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ä»¥ä¸‹ã‚’è¨­å®š\n",
        "   - `WANDB_API_KEY`: WandB APIã‚­ãƒ¼\n",
        "   - `HF_TOKEN`: Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "3. **Google Drive**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ`archive_batch_xxxx.zip` å½¢å¼ï¼‰ã‚’é…ç½®\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ ä½¿ã„æ–¹\n",
        "\n",
        "1. ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ\n",
        "2. ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰è‡ªå‹•çš„ã«APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "3. WandBã§å­¦ç¿’é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–: https://wandb.ai/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff6e8f3d",
      "metadata": {
        "id": "ff6e8f3d"
      },
      "source": [
        "# ã‚»ãƒ« 1 â€” ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e81e6e23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e81e6e23",
        "outputId": "c3bab45b-9b53-4429-f2da-d7d0641db5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch==2.3.0+cu118 in /usr/local/lib/python3.12/dist-packages (2.3.0+cu118)\n",
            "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu118) (11.8.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu118) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu118) (1.3.0)\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "pkg-config is already the newest version (0.29.2-1ubuntu3).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavcodec-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavdevice-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavfilter-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavformat-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavutil-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libswresample-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libswscale-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: encodec in /usr/local/lib/python3.12/dist-packages (0.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from encodec) (2.3.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from encodec) (2.3.0+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from encodec) (0.8.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.12/dist-packages (from torch->encodec) (11.8.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->encodec) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->encodec) (1.3.0)\n",
            "Using pip 25.3 from /usr/local/lib/python3.12/dist-packages/pip (python 3.12)\n",
            "Requirement already satisfied: av==11.0.0 in /usr/local/lib/python3.12/dist-packages (11.0.0)\n",
            "Collecting git+https://github.com/facebookresearch/audiocraft.git@main\n",
            "  Cloning https://github.com/facebookresearch/audiocraft.git (to revision main) to /tmp/pip-req-build-n90yho8a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/audiocraft.git /tmp/pip-req-build-n90yho8a\n",
            "  Resolved https://github.com/facebookresearch/audiocraft.git to commit 896ec7c47f5e5d1e5aa1e4b260c4405328bf009d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.12/dist-packages (0.18.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: loralib in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed) (0.8.1)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.12/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.1.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.12.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.3.0+cu118)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.8.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->deepspeed) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
          ]
        }
      ],
      "source": [
        "# å®Ÿè¡Œå‰ã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã® GPU ã‚’ç¢ºèªã€‚CUDA ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã‚ã›ã¦ torch ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚\n",
        "# Colabã®ç’°å¢ƒã«åˆã‚ã›ã¦ã€åˆ©ç”¨å¯èƒ½ãªæœ€æ–°ã®cu118å¯¾å¿œPyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°ã€‚\n",
        "# ä¾‹ï¼šCUDA 11.8 / PyTorch 2.3 ã®å ´åˆ\n",
        "!pip install --upgrade pip\n",
        "!pip install torch==2.3.0+cu118 torchaudio==2.3.0 --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!apt-get update && apt-get install -y ffmpeg build-essential pkg-config libavformat-dev libavcodec-dev libavdevice-dev libavfilter-dev libavutil-dev libswresample-dev libswscale-dev\n",
        "\n",
        "# audiocraft ã®ä¾å­˜é–¢ä¿‚ã‚’å…ˆã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ç«¶åˆã‚’å›é¿\n",
        "!pip install soundfile librosa encodec\n",
        "\n",
        "# av ã®ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å…ˆã« av ã‚’æ˜ç¤ºçš„ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "# audiocraft ã® requirements ã« av==11.0.0 ãŒã‚ã‚‹ãŸã‚ã€ãã‚Œã‚’æŒ‡å®š\n",
        "!pip install av==11.0.0 --verbose\n",
        "\n",
        "# audiocraft (MusicGen ã‚’å«ã‚€) å…¬å¼ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰\n",
        "# av ã‚’å…ˆã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ã‚‹ã®ã§ã€ --no-deps ã‚’ã¤ã‘ã¦ä¾å­˜é–¢ä¿‚ã®å†ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—\n",
        "!pip install -U git+https://github.com/facebookresearch/audiocraft.git@main --no-deps\n",
        "\n",
        "# LoRA / DeepSpeed / WandB ãªã©\n",
        "!pip install deepspeed wandb loralib tqdm\n",
        "\n",
        "print(\"ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d6290e",
      "metadata": {
        "id": "11d6290e"
      },
      "source": [
        "# ã‚»ãƒ« 2 â€” Drive ãƒã‚¦ãƒ³ãƒˆã¨è¨­å®š\n",
        "\n",
        "Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "53bd8d67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53bd8d67",
        "outputId": "3f2545e2-ce3e-4236-8fcb-62487e1fd66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ZIPæ ¼ç´å ´æ‰€: /content/drive/MyDrive/Archive_Wavs\n",
            "ä¸€æ™‚å±•é–‹å…ˆ: /content/temp_dataset\n",
            "ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜å…ˆ: /content/drive/MyDrive/MusicGen_Tokens\n",
            "æ¤œå‡ºã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«æ•°: 139\n",
            "ä¾‹: archive_batch_0001.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# è¨­å®š\n",
        "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "DRIVE_ARCHIVE_DIR = '/content/drive/MyDrive/Archive_Wavs'\n",
        "\n",
        "# ä¸€æ™‚å±•é–‹å…ˆï¼ˆColabãƒ­ãƒ¼ã‚«ãƒ«ï¼‰\n",
        "TEMP_DATA_DIR = '/content/temp_dataset'\n",
        "\n",
        "# ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜å…ˆï¼ˆGoogle Driveæ¨å¥¨ã€ã¾ãŸã¯å®¹é‡ãŒã‚ã‚Œã°ãƒ­ãƒ¼ã‚«ãƒ«ï¼‰\n",
        "# â€»å†é–‹å¯èƒ½ã«ã™ã‚‹ãŸã‚Driveæ¨å¥¨ã§ã™ãŒã€I/OãŒé…ã„å ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ã«ã—ã¦æœ€å¾Œã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹æˆ¦ç•¥ã‚‚å¯\n",
        "# ã“ã“ã§ã¯Driveã«ç›´æ¥ä¿å­˜ã™ã‚‹è¨­å®šã«ã—ã¾ã™\n",
        "TOKEN_DIR = '/content/drive/MyDrive/MusicGen_Tokens'\n",
        "\n",
        "os.makedirs(TOKEN_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(f'ZIPæ ¼ç´å ´æ‰€: {DRIVE_ARCHIVE_DIR}')\n",
        "print(f'ä¸€æ™‚å±•é–‹å…ˆ: {TEMP_DATA_DIR}')\n",
        "print(f'ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜å…ˆ: {TOKEN_DIR}')\n",
        "\n",
        "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
        "zip_files = sorted(list(Path(DRIVE_ARCHIVE_DIR).glob('archive_batch_*.zip')))\n",
        "print(f'æ¤œå‡ºã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(zip_files)}')\n",
        "if len(zip_files) > 0:\n",
        "    print(f'ä¾‹: {zip_files[0].name}')\n",
        "else:\n",
        "    print('âš ï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b1cecb",
      "metadata": {
        "id": "d8b1cecb"
      },
      "source": [
        "# ã‚»ãƒ« 2.5 â€” WandBã¨Hugging Faceã®èªè¨¼è¨­å®š\n",
        "\n",
        "ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0df137c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0df137c8",
        "outputId": "a6aa5ec4-40f0-4150-97c1-c0c02332238e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcharge0315\u001b[0m (\u001b[33mcharge0315-personal\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ WandBã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ\n",
            "âœ“ Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ã¾ã—ãŸ\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "try:\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "    # WandBãƒ­ã‚°ã‚¤ãƒ³\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "    print(\"âœ“ WandBã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ\")\n",
        "\n",
        "    # Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®š\n",
        "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "    print(\"âœ“ Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ã¾ã—ãŸ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "    print(\"Colabã®ã€Œã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:\")\n",
        "    print(\"  - WANDB_API_KEY: WandBã®APIã‚­ãƒ¼\")\n",
        "    print(\"  - HF_TOKEN: Hugging Faceã®APIãƒˆãƒ¼ã‚¯ãƒ³\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e6e1451",
      "metadata": {
        "id": "1e6e1451"
      },
      "source": [
        "# ã‚»ãƒ« 2.6 â€” ğŸ§ª å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ\n",
        "\n",
        "æœ€åˆã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å°‘æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡ºã—ã¦ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®å‹•ä½œç¢ºèªã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a3cdaf43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "a3cdaf43",
        "outputId": "6e9e5524-1974-4b95-d206-9854bdff8ce1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'audiocraft'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1722089373.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maudiocraft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompressionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMusicGen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloralib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'audiocraft'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchaudio\n",
        "from audiocraft.models import CompressionModel, MusicGen\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import loralib as lora\n",
        "import torch.nn as nn\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆè¨­å®š\n",
        "TEST_MODE = True\n",
        "NUM_TEST_SAMPLES = 5\n",
        "TEST_EPOCHS = 2\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ§ª å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "TEST_DIR = '/content/test_workspace'\n",
        "TEST_WAV_DIR = os.path.join(TEST_DIR, 'wavs')\n",
        "TEST_TOKEN_DIR = os.path.join(TEST_DIR, 'tokens')\n",
        "os.makedirs(TEST_WAV_DIR, exist_ok=True)\n",
        "os.makedirs(TEST_TOKEN_DIR, exist_ok=True)\n",
        "\n",
        "# 1. ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºï¼ˆæœ€åˆã®ZIPã‹ã‚‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ï¼‰\n",
        "print(\"ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\")\n",
        "if len(zip_files) > 0:\n",
        "    target_zip = zip_files[0]\n",
        "    print(f\"  ZIPãƒ•ã‚¡ã‚¤ãƒ«: {target_zip.name}\")\n",
        "    # ä¸€æ™‚çš„ã«å±•é–‹ã—ã¦æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã‚³ãƒ”ãƒ¼\n",
        "    !mkdir -p /content/temp_extract\n",
        "    !tar -xzf \"{target_zip}\" -C /content/temp_extract\n",
        "\n",
        "    extracted_files = list(Path('/content/temp_extract').rglob('*.wav'))\n",
        "    print(f\"  æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(extracted_files)}\")\n",
        "\n",
        "    for i, f in enumerate(extracted_files[:NUM_TEST_SAMPLES]):\n",
        "        shutil.copy(f, TEST_WAV_DIR)\n",
        "        print(f\"  ã‚³ãƒ”ãƒ¼: {f.name}\")\n",
        "\n",
        "    # æƒé™¤\n",
        "    !rm -rf /content/temp_extract\n",
        "else:\n",
        "    print(\"âš ï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™\")\n",
        "    # ãƒ€ãƒŸãƒ¼WAVä½œæˆï¼ˆæ­£å¼¦æ³¢ï¼‰\n",
        "    sr = 32000\n",
        "    for i in range(NUM_TEST_SAMPLES):\n",
        "        t = torch.linspace(0, 5, sr * 5)\n",
        "        wav = torch.sin(2 * 3.14159 * 440 * t).unsqueeze(0)\n",
        "        torchaudio.save(os.path.join(TEST_WAV_DIR, f'test_{i}.wav'), wav, sr)\n",
        "\n",
        "test_paths = list(Path(TEST_WAV_DIR).glob('*.wav'))\n",
        "print(f\"âœ“ {len(test_paths)}å€‹ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„\")\n",
        "print()\n",
        "\n",
        "# 2. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸµ ã‚¹ãƒ†ãƒƒãƒ—2: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ\")\n",
        "compression_model = CompressionModel.get_pretrained('facebook/encodec_32khz')\n",
        "compression_model.to('cuda')\n",
        "compression_model.eval()\n",
        "\n",
        "for i, p in enumerate(test_paths):\n",
        "    try:\n",
        "        wav, sr = torchaudio.load(p)\n",
        "        if sr != 32000:\n",
        "            resampler = torchaudio.transforms.Resample(sr, 32000)\n",
        "            wav = resampler(wav)\n",
        "        if wav.shape[0] > 1:\n",
        "            wav = wav.mean(dim=0, keepdim=True)\n",
        "        wav = wav.unsqueeze(0).to('cuda')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            encoded_frames = compression_model.encode(wav)\n",
        "            tokens = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)\n",
        "\n",
        "        outp = os.path.join(TEST_TOKEN_DIR, p.stem + '.pt')\n",
        "        torch.save({'tokens': tokens.cpu(), 'path': str(p)}, outp)\n",
        "        print(f\"  âœ“ ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å®Œäº†: {p.name} -> {tokens.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âœ— ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "\n",
        "del compression_model\n",
        "torch.cuda.empty_cache()\n",
        "print()\n",
        "\n",
        "# 3. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ“¦ ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "class TestTokenDataset(Dataset):\n",
        "    def __init__(self, token_dir, max_length=1500):\n",
        "        self.files = sorted(list(Path(token_dir).glob('*.pt')))\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.load(self.files[idx])\n",
        "        tokens = data['tokens']\n",
        "        if tokens.dim() == 3: tokens = tokens.squeeze(0)\n",
        "        seq_len = tokens.shape[-1]\n",
        "        if seq_len > self.max_length:\n",
        "            tokens = tokens[:, :self.max_length]\n",
        "        elif seq_len < self.max_length:\n",
        "            pad = self.max_length - seq_len\n",
        "            tokens = torch.nn.functional.pad(tokens, (0, pad), value=0)\n",
        "        return tokens\n",
        "\n",
        "test_dataset = TestTokenDataset(TEST_TOKEN_DIR)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
        "for batch in test_loader:\n",
        "    print(f\"âœ“ ãƒãƒƒãƒå½¢çŠ¶: {batch.shape}\")\n",
        "    break\n",
        "print()\n",
        "\n",
        "# 4. ãƒ¢ãƒ‡ãƒ«ã¨LoRAã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¨LoRAé©ç”¨ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "model.to('cuda')\n",
        "model.eval()\n",
        "\n",
        "def apply_lora_to_linear(module, r=8, lora_alpha=32, lora_dropout=0.1, parent_name='', count=[0]):\n",
        "    for name, child in list(module.named_children()):\n",
        "        if isinstance(child, nn.Linear) and count[0] < 3:  # ãƒ†ã‚¹ãƒˆç”¨åˆ¶é™\n",
        "            lora_linear = lora.Linear(child.in_features, child.out_features, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, bias=(child.bias is not None))\n",
        "            lora_linear.weight.data = child.weight.data.clone()\n",
        "            if child.bias is not None: lora_linear.bias.data = child.bias.data.clone()\n",
        "            setattr(module, name, lora_linear)\n",
        "            count[0] += 1\n",
        "            print(f\"  âœ“ LoRAé©ç”¨: {parent_name}.{name}\")\n",
        "        else:\n",
        "            apply_lora_to_linear(child, r, lora_alpha, lora_dropout, f\"{parent_name}.{name}\" if parent_name else name, count)\n",
        "\n",
        "apply_lora_to_linear(model.lm, r=8)\n",
        "print(\"âœ“ LoRAé©ç”¨å®Œäº†\")\n",
        "print()\n",
        "\n",
        "# 5. å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ‹ï¸ ã‚¹ãƒ†ãƒƒãƒ—5: å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "model.train()\n",
        "for epoch in range(TEST_EPOCHS):\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to('cuda')\n",
        "        out = model.lm.forward(batch)\n",
        "        loss = criterion(out, batch.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        print(f\"  Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "        break\n",
        "print()\n",
        "\n",
        "# 6. ç”Ÿæˆãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ¶ ã‚¹ãƒ†ãƒƒãƒ—6: ç”Ÿæˆãƒ†ã‚¹ãƒˆ\")\n",
        "model.eval()\n",
        "model.set_generation_params(duration=5)\n",
        "with torch.no_grad():\n",
        "    wav = model.generate([\"Test melody\"])\n",
        "print(f\"âœ“ ç”Ÿæˆå®Œäº†: {wav.shape}\")\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "print(\"âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88cf0992",
      "metadata": {
        "id": "88cf0992"
      },
      "source": [
        "# ã‚»ãƒ« 3 â€” é †æ¬¡å‡¦ç†ã«ã‚ˆã‚‹ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º (Sequential Tokenization)\n",
        "\n",
        "**æˆ¦ç•¥**: ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ãšã¤å±•é–‹ â†’ ãƒˆãƒ¼ã‚¯ãƒ³åŒ– â†’ WAVå‰Šé™¤ ã‚’ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚\n",
        "ã“ã‚Œã«ã‚ˆã‚Šã€Colabã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’åœ§è¿«ã›ãšã«å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã§ãã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de228b0",
      "metadata": {
        "id": "0de228b0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import shutil\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from audiocraft.models import CompressionModel\n",
        "import wandb\n",
        "\n",
        "# WandBåˆæœŸåŒ–\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    if not wandb.api.api_key: wandb.login(key=WANDB_API_KEY)\n",
        "    wandb.init(project='musicgen-lora-finetune', name='sequential_tokenization', job_type='preprocessing')\n",
        "    use_wandb = True\n",
        "except: use_wandb = False\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
        "print('EnCodecãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "compression_model = CompressionModel.get_pretrained('facebook/encodec_32khz')\n",
        "compression_model.to('cuda')\n",
        "compression_model.eval()\n",
        "\n",
        "# å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
        "existing_tokens = set([Path(f).stem for f in glob.glob(os.path.join(TOKEN_DIR, '*.pt'))])\n",
        "print(f'æ—¢ã«ãƒˆãƒ¼ã‚¯ãƒ³åŒ–æ¸ˆã¿: {len(existing_tokens)} ãƒ•ã‚¡ã‚¤ãƒ«')\n",
        "\n",
        "total_processed = 0\n",
        "start_time = time.time()\n",
        "\n",
        "# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®ãƒ«ãƒ¼ãƒ—\n",
        "for zip_idx, zip_file in enumerate(tqdm(zip_files, desc='ZIPãƒãƒƒãƒå‡¦ç†')):\n",
        "    print(f'\\nğŸ“¦ å‡¦ç†ä¸­: {zip_file.name} ({zip_idx+1}/{len(zip_files)})')\n",
        "\n",
        "    # 1. å±•é–‹ (Extract)\n",
        "    if os.path.exists(TEMP_DATA_DIR):\n",
        "        shutil.rmtree(TEMP_DATA_DIR)\n",
        "    os.makedirs(TEMP_DATA_DIR, exist_ok=True)\n",
        "\n",
        "    print('  â†³ å±•é–‹ä¸­...')\n",
        "    !tar -xzf \"{zip_file}\" -C \"{TEMP_DATA_DIR}\"\n",
        "\n",
        "    wav_files = list(Path(TEMP_DATA_DIR).rglob('*.wav'))\n",
        "    print(f'  â†³ {len(wav_files)} å€‹ã®WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º')\n",
        "\n",
        "    # 2. ãƒˆãƒ¼ã‚¯ãƒ³åŒ– (Tokenize)\n",
        "    batch_processed = 0\n",
        "    for wav_path in tqdm(wav_files, desc='  â†³ ãƒˆãƒ¼ã‚¯ãƒ³åŒ–', leave=False):\n",
        "        if wav_path.stem in existing_tokens:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            wav, sr = torchaudio.load(str(wav_path))\n",
        "            if sr != 32000:\n",
        "                resampler = torchaudio.transforms.Resample(sr, 32000)\n",
        "                wav = resampler(wav)\n",
        "            if wav.shape[0] > 1:\n",
        "                wav = wav.mean(dim=0, keepdim=True)\n",
        "            wav = wav.unsqueeze(0).to('cuda')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                encoded_frames = compression_model.encode(wav)\n",
        "                tokens = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)\n",
        "\n",
        "            outp = os.path.join(TOKEN_DIR, wav_path.stem + '.pt')\n",
        "            torch.save({'tokens': tokens.cpu(), 'path': str(wav_path)}, outp)\n",
        "\n",
        "            batch_processed += 1\n",
        "            total_processed += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Error: {wav_path.name} - {e}')\n",
        "            continue\n",
        "\n",
        "    # 3. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— (Cleanup)\n",
        "    print('  â†³ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...')\n",
        "    shutil.rmtree(TEMP_DATA_DIR)\n",
        "\n",
        "    # ãƒ­ã‚°\n",
        "    if use_wandb:\n",
        "        wandb.log({\n",
        "            'processed_files': total_processed,\n",
        "            'processed_zips': zip_idx + 1,\n",
        "            'files_in_batch': batch_processed\n",
        "        })\n",
        "\n",
        "print(f'\\nâœ… å…¨å‡¦ç†å®Œäº†: {total_processed} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°è¦ã«ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¾ã—ãŸ')\n",
        "if use_wandb: wandb.finish()\n",
        "\n",
        "del compression_model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7a3f7af",
      "metadata": {
        "id": "f7a3f7af"
      },
      "source": [
        "# ã‚»ãƒ« 4 â€” DeepSpeed è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2b74acb",
      "metadata": {
        "id": "e2b74acb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "ds_config = {\n",
        "  \"train_batch_size\": 16,\n",
        "  \"train_micro_batch_size_per_gpu\": 2,\n",
        "  \"gradient_accumulation_steps\": 8,\n",
        "  \"optimizer\": {\n",
        "    \"type\": \"AdamW\",\n",
        "    \"params\": {\n",
        "      \"lr\": 1e-4,\n",
        "      \"weight_decay\": 0.01\n",
        "    }\n",
        "  },\n",
        "  \"fp16\": {\n",
        "    \"enabled\": True\n",
        "  },\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 3,\n",
        "    \"offload_optimizer\": {\n",
        "      \"device\": \"cpu\",\n",
        "      \"pin_memory\": True\n",
        "    },\n",
        "    \"offload_param\": {\n",
        "      \"device\": \"cpu\"\n",
        "    },\n",
        "    \"overlap_comm\": True,\n",
        "    \"contiguous_gradients\": True\n",
        "  }\n",
        "}\n",
        "\n",
        "with open('ds_config.json','w') as f:\n",
        "    json.dump(ds_config, f, indent=2)\n",
        "\n",
        "print('ds_config.json ã‚’ä½œæˆã—ã¾ã—ãŸ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2967cb7b",
      "metadata": {
        "id": "2967cb7b"
      },
      "source": [
        "# ã‚»ãƒ« 5 â€” ãƒ¢ãƒ‡ãƒ«æº–å‚™ã¨LoRAé©ç”¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0395dd07",
      "metadata": {
        "id": "0395dd07"
      },
      "outputs": [],
      "source": [
        "import loralib as lora\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from audiocraft.models import MusicGen\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
        "print('MusicGen-Large ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "model.eval()\n",
        "\n",
        "# LoRAé©ç”¨é–¢æ•°\n",
        "def apply_lora_to_linear(module, r=8, lora_alpha=32, lora_dropout=0.1, parent_name=''):\n",
        "    for name, child in list(module.named_children()):\n",
        "        full_name = f\"{parent_name}.{name}\" if parent_name else name\n",
        "        if isinstance(child, nn.Linear):\n",
        "            lora_linear = lora.Linear(\n",
        "                child.in_features, child.out_features, r=r,\n",
        "                lora_alpha=lora_alpha, lora_dropout=lora_dropout, bias=(child.bias is not None)\n",
        "            )\n",
        "            lora_linear.weight.data = child.weight.data.clone()\n",
        "            if child.bias is not None:\n",
        "                lora_linear.bias.data = child.bias.data.clone()\n",
        "            setattr(module, name, lora_linear)\n",
        "            print(f'Applied LoRA to: {full_name}')\n",
        "        else:\n",
        "            apply_lora_to_linear(child, r, lora_alpha, lora_dropout, full_name)\n",
        "\n",
        "print('\\nLoRAã‚’é©ç”¨ä¸­...')\n",
        "apply_lora_to_linear(model.lm, r=8)\n",
        "\n",
        "# å‹¾é…è¨­å®š\n",
        "for p in model.parameters(): p.requires_grad = False\n",
        "for name, p in model.named_parameters():\n",
        "    if 'lora_' in name: p.requires_grad = True\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f'\\nå­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41971f7b",
      "metadata": {
        "id": "41971f7b"
      },
      "source": [
        "# ã‚»ãƒ« 6 â€” ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ä½œæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba719a13",
      "metadata": {
        "id": "ba719a13"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "class TokenDataset(Dataset):\n",
        "    def __init__(self, token_dir, max_length=1500):\n",
        "        self.files = sorted(list(Path(token_dir).glob('*.pt')))\n",
        "        self.max_length = max_length\n",
        "        print(f'Dataset initialized with {len(self.files)} samples')\n",
        "\n",
        "    def __len__(self): return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.load(self.files[idx])\n",
        "        tokens = data['tokens']\n",
        "        if tokens.dim() == 3: tokens = tokens.squeeze(0)\n",
        "\n",
        "        seq_len = tokens.shape[-1]\n",
        "        if seq_len > self.max_length:\n",
        "            start = random.randint(0, seq_len - self.max_length)\n",
        "            tokens = tokens[:, start:start + self.max_length]\n",
        "        elif seq_len < self.max_length:\n",
        "            pad = self.max_length - seq_len\n",
        "            tokens = torch.nn.functional.pad(tokens, (0, pad), value=0)\n",
        "        return tokens\n",
        "\n",
        "dataset = TokenDataset(TOKEN_DIR, max_length=1500)\n",
        "train_size = int(0.95 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f'Train: {len(train_dataset)}, Valid: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da7a627b",
      "metadata": {
        "id": "da7a627b"
      },
      "source": [
        "# ã‚»ãƒ« 7 â€” å­¦ç¿’ãƒ«ãƒ¼ãƒ— (WandB + Checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47016277",
      "metadata": {
        "id": "47016277"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "# WandBåˆæœŸåŒ–\n",
        "try:\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    if not wandb.api.api_key: wandb.login(key=WANDB_API_KEY)\n",
        "    wandb.init(project='musicgen-lora-finetune', name='training_run', tags=['musicgen', 'lora', 'a100'])\n",
        "    use_wandb = True\n",
        "except: use_wandb = False\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=0.01)\n",
        "\n",
        "# ä¿å­˜å…ˆè¨­å®š\n",
        "CKPT_DIR = '/content/drive/MyDrive/MusicGen_Checkpoints'\n",
        "LORA_DIR = os.path.join(CKPT_DIR, 'lora_weights')\n",
        "FULL_MODEL_DIR = os.path.join(CKPT_DIR, 'full_models')\n",
        "os.makedirs(LORA_DIR, exist_ok=True)\n",
        "os.makedirs(FULL_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "def extract_lora_weights(model):\n",
        "    return {name: param.cpu().detach().clone() for name, param in model.named_parameters() if 'lora_' in name and param.requires_grad}\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, global_step, loss, checkpoint_type='regular'):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch, 'global_step': global_step, 'model_state': model.state_dict(),\n",
        "        'opt_state': optimizer.state_dict(), 'loss': loss, 'best_loss': best_loss,\n",
        "        'timestamp': time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    }\n",
        "    lora_checkpoint = {\n",
        "        'epoch': epoch, 'global_step': global_step, 'lora_weights': extract_lora_weights(model),\n",
        "        'loss': loss, 'timestamp': checkpoint['timestamp']\n",
        "    }\n",
        "\n",
        "    if checkpoint_type == 'regular':\n",
        "        torch.save(checkpoint, os.path.join(CKPT_DIR, 'latest.pt'))\n",
        "        torch.save(lora_checkpoint, os.path.join(LORA_DIR, 'latest_lora.pt'))\n",
        "    elif checkpoint_type == 'best':\n",
        "        torch.save(checkpoint, os.path.join(FULL_MODEL_DIR, 'best_model.pt'))\n",
        "        torch.save(lora_checkpoint, os.path.join(LORA_DIR, 'best_lora.pt'))\n",
        "        print(f'  ğŸ† ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜: Loss {loss:.4f}')\n",
        "    elif checkpoint_type == 'epoch':\n",
        "        torch.save(checkpoint, os.path.join(FULL_MODEL_DIR, f'checkpoint_epoch_{epoch+1}.pt'))\n",
        "        torch.save(lora_checkpoint, os.path.join(LORA_DIR, f'lora_epoch_{epoch+1}.pt'))\n",
        "    elif checkpoint_type == 'step':\n",
        "        torch.save(checkpoint, os.path.join(CKPT_DIR, f'checkpoint_step_{global_step}.pt'))\n",
        "\n",
        "# å†é–‹å‡¦ç†\n",
        "start_epoch = 0\n",
        "global_step = 0\n",
        "best_loss = float('inf')\n",
        "latest_ckpt = os.path.join(CKPT_DIR, 'latest.pt')\n",
        "if os.path.exists(latest_ckpt):\n",
        "    print(f'ğŸ”„ å†é–‹: {latest_ckpt}')\n",
        "    ckpt = torch.load(latest_ckpt, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model_state'], strict=False)\n",
        "    optimizer.load_state_dict(ckpt['opt_state'])\n",
        "    start_epoch = ckpt['epoch'] + 1\n",
        "    global_step = ckpt.get('global_step', 0)\n",
        "    best_loss = ckpt.get('best_loss', float('inf'))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "num_epochs = 5\n",
        "accum_steps = 8\n",
        "\n",
        "print('\\nğŸš€ å­¦ç¿’é–‹å§‹')\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "    for batch_idx, tokens in enumerate(pbar):\n",
        "        try:\n",
        "            tokens = tokens.to(device)\n",
        "            outputs = model.lm.forward(tokens)\n",
        "            loss = criterion(outputs, tokens.float()) / accum_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (batch_idx + 1) % accum_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if use_wandb and global_step % 10 == 0:\n",
        "                    wandb.log({'train/loss': loss.item() * accum_steps, 'train/step': global_step})\n",
        "                if global_step % 500 == 0:\n",
        "                    save_checkpoint(model, optimizer, epoch, global_step, loss.item() * accum_steps, 'step')\n",
        "\n",
        "            epoch_loss += loss.item() * accum_steps\n",
        "            pbar.set_postfix({'loss': f'{loss.item() * accum_steps:.4f}'})\n",
        "        except Exception as e:\n",
        "            print(f'Error: {e}')\n",
        "            continue\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f'\\nEpoch {epoch+1} Loss: {avg_loss:.4f}')\n",
        "\n",
        "    if use_wandb: wandb.log({'epoch/loss': avg_loss, 'epoch': epoch+1})\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        save_checkpoint(model, optimizer, epoch, global_step, avg_loss, 'best')\n",
        "\n",
        "    save_checkpoint(model, optimizer, epoch, global_step, avg_loss, 'regular')\n",
        "    save_checkpoint(model, optimizer, epoch, global_step, avg_loss, 'epoch')\n",
        "\n",
        "print('ğŸ‰ å­¦ç¿’å®Œäº†')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0353a749",
      "metadata": {
        "id": "0353a749"
      },
      "source": [
        "# ã‚»ãƒ« 8 â€” æ¥½æ›²ç”Ÿæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e68fad",
      "metadata": {
        "id": "68e68fad"
      },
      "outputs": [],
      "source": [
        "from audiocraft.data.audio import audio_write\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "print('ğŸµ æ¥½æ›²ç”Ÿæˆ')\n",
        "model.eval()\n",
        "model.set_generation_params(use_sampling=True, top_k=250, duration=30)\n",
        "\n",
        "prompts = [\n",
        "    \"A dynamic heavy metal song with fast drums and guitar solo\",\n",
        "    \"Relaxing jazz piano with soft background ambience\",\n",
        "    \"Upbeat electronic dance music with strong bass\"\n",
        "]\n",
        "\n",
        "with torch.no_grad():\n",
        "    wav = model.generate(prompts)\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/MusicGen_Generated'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for idx, one_wav in enumerate(wav):\n",
        "    filename = os.path.join(output_dir, f\"generated_{idx}\")\n",
        "    audio_write(filename, one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    print(f'\\nPrompt: {prompts[idx]}')\n",
        "    display(Audio(filename + \".wav\"))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}