{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# MusicGen-Large ファインチューニング & 生成ノートブック\n",
        "\n",
        "このノートブックでは、Facebook (Meta) の `audiocraft` ライブラリを使用して、MusicGen-Largeモデルを独自のデータセット（約17,000曲）でファインチューニングし、その後、学習したモデルを使って楽曲生成を行います。\n",
        "\n",
        "**前提条件:**\n",
        "1.  Google Colabのランタイムタイプを **GPU** に設定してください。（MusicGen-Largeはメモリを大量に消費するため、**A100 GPU** の使用を強く推奨します。V100でも設定次第では動作しますが、T4ではメモリ不足になる可能性が高いです。）\n",
        "2.  Google Driveに以下のフォルダ構成でデータを配置してください。\n",
        "    *   `My Drive/MusicGen_Dataset/`\n",
        "        *   `audio/` (wavファイルを格納)\n",
        "        *   `metadata.jsonl` (提供された形式のJSONLファイル)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 環境構築 (Environment Setup)\n",
        "必要なライブラリ (`audiocraft`, `xformers` 等) をインストールし、リポジトリをクローンします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "env-setup"
      },
      "outputs": [],
      "source": [
        "# @title 環境構築とライブラリのインストール\n",
        "# 必要な依存関係をインストールします\n",
        "!pip install -U pip\n",
        "!pip install -U autopep8\n",
        "\n",
        "# PyTorchとAudioCraftのインストール\n",
        "# ColabのCUDAバージョンに合わせてxformersをインストール（高速化のため重要）\n",
        "!pip install -U xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -U audiocraft\n",
        "!pip install wandb\n",
        "\n",
        "# ソースコードから最新機能を使うためにclone（設定ファイル参照のためにも必要）\n",
        "!git clone https://github.com/facebookresearch/audiocraft.git\n",
        "%cd audiocraft\n",
        "!pip install -e .\n",
        "\n",
        "print(\"インストールが完了しました。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (オプション) 素のMusicGenモデルでの生成テスト\n",
        "ファインチューニングを行う前に、オリジナルの `facebook/musicgen-large` モデルでどのような曲が生成されるか確認できます。\n",
        "※このセルを実行するとモデルがメモリにロードされます。ファインチューニング実行前にメモリ不足になる可能性があるため、確認後は「ランタイムの再起動」を行うことを推奨します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "base-model-demo"
      },
      "outputs": [],
      "source": [
        "# @title 素のMusicGen-Largeで生成テスト\n",
        "from audiocraft.models import MusicGen\n",
        "from audiocraft.data.audio import audio_write\n",
        "from IPython.display import Audio, display\n",
        "import torch\n",
        "\n",
        "# モデルのロード (facebook/musicgen-large)\n",
        "print(\"素のモデルをロード中...\")\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "\n",
        "# 生成パラメータ設定\n",
        "model.set_generation_params(\n",
        "    use_sampling=True,\n",
        "    top_k=250,\n",
        "    duration=10  # テスト用に10秒\n",
        ")\n",
        "\n",
        "# プロンプト (自由に書き換えてください)\n",
        "descriptions = [\n",
        "    \"A dynamic heavy metal song with fast drums and guitar solo\",\n",
        "    \"Relaxing jazz piano with soft rain background\",\n",
        "]\n",
        "\n",
        "print(\"生成中...\")\n",
        "wav = model.generate(descriptions)\n",
        "\n",
        "# 再生\n",
        "for idx, one_wav in enumerate(wav):\n",
        "    filename = f\"base_generated_{idx}\"\n",
        "    audio_write(filename, one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    print(f\"\\nPrompt: {descriptions[idx]}\")\n",
        "    display(Audio(filename + \".wav\"))\n",
        "\n",
        "# メモリ解放 (念のため)\n",
        "del model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Google Driveのマウント (Mount Google Drive)\n",
        "データセットの読み込みと、学習済みモデルの保存先としてGoogle Driveをマウントします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount-drive"
      },
      "outputs": [],
      "source": [
        "# @title Google Driveのマウント\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 作業用ディレクトリの設定（必要に応じて変更してください）\n",
        "dataset_root = '/content/drive/MyDrive/MusicGen_Dataset'\n",
        "output_dir = '/content/drive/MyDrive/MusicGen_Checkpoints'\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# データセットの解凍 (tar.gz -> local)\n",
        "# Google DriveのI/O制限を回避するため、ローカルにコピーして解凍します\n",
        "tar_path = '/content/drive/MyDrive/MusicGen_Dataset/dataset.tar.gz'\n",
        "local_dataset_root = '/content/dataset'\n",
        "\n",
        "if os.path.exists(tar_path):\n",
        "    print(f\"データセットをコピー中...: {tar_path}\")\n",
        "    !cp \"{tar_path}\" /content/dataset.tar.gz\n",
        "    \n",
        "    print(\"解凍中...\")\n",
        "    !mkdir -p \"{local_dataset_root}\"\n",
        "    !tar -xzf /content/dataset.tar.gz -C \"{local_dataset_root}\"\n",
        "    print(f\"解凍完了: {local_dataset_root}\")\n",
        "else:\n",
        "    print(f\"警告: データセットアーカイブが見つかりません: {tar_path}\")\n",
        "    # フォールバック: Driveを直接参照 (遅い可能性があります)\n",
        "    local_dataset_root = dataset_root\n",
        "\n",
        "print(f\"データセットパス(Original): {dataset_root}\")\n",
        "print(f\"データセットパス(Local): {local_dataset_root}\")\n",
        "print(f\"モデル保存先: {output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. データセットの準備 (Dataset Preparation)\n",
        "提供されたJSONLファイルを読み込み、Audiocraftが学習に使用できる形式に変換します。\n",
        "ここでは、学習用(train)と検証用(valid)にデータを分割し、パスを絶対パスに書き換えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data-prep"
      },
      "outputs": [],
      "source": [
        "# @title データセットのマニフェスト作成\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# 設定\n",
        "input_jsonl = Path(dataset_root) / 'metadata.jsonl'\n",
        "train_jsonl = Path(dataset_root) / 'train.jsonl'\n",
        "valid_jsonl = Path(dataset_root) / 'valid.jsonl'\n",
        "validation_split = 0.05  # 5%を検証用に回す\n",
        "\n",
        "# データの読み込みと変換\n",
        "data = []\n",
        "if not input_jsonl.exists():\n",
        "    print(f\"エラー: {input_jsonl} が見つかりません。パスを確認してください。\")\n",
        "else:\n",
        "    with open(input_jsonl, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            item = json.loads(line)\n",
        "            # パスをローカルパスに変換\n",
        "            # JSONL内のパス: /content/drive/MyDrive/MusicGen_Dataset/...\n",
        "            # ローカルパス: /content/dataset/...\n",
        "            original_path = item['path']\n",
        "            # Drive上のパスプレフィックスを削除して、ローカルのルートと結合\n",
        "            relative_path = original_path.replace('/content/drive/MyDrive/MusicGen_Dataset/', '').lstrip('/')\n",
        "            abs_path = Path(local_dataset_root) / relative_path\n",
        "            \n",
        "            if abs_path.exists():\n",
        "                # Audiocraftに必要なフィールドを整理\n",
        "                entry = {\n",
        "                    \"path\": str(abs_path),\n",
        "                    \"duration\": item.get(\"duration\", 30.0),\n",
        "                    \"sample_rate\": item.get(\"sample_rate\", 32000),\n",
        "                    \"amplitude\": item.get(\"amplitude\", None),\n",
        "                    \"description\": item.get(\"description\", \"\"),\n",
        "                }\n",
        "                data.append(entry)\n",
        "            else:\n",
        "                print(f\"警告: 音声ファイルが見つかりません - {abs_path}\")\n",
        "\n",
        "    # シャッフルして分割\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data) * (1 - validation_split))\n",
        "    train_data = data[:split_idx]\n",
        "    valid_data = data[split_idx:]\n",
        "\n",
        "    # 保存\n",
        "    def save_jsonl(data_list, output_path):\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            for entry in data_list:\n",
        "                f.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "    save_jsonl(train_data, train_jsonl)\n",
        "    save_jsonl(valid_data, valid_jsonl)\n",
        "\n",
        "    print(f\"データセット準備完了:\")\n",
        "    print(f\"  Train: {len(train_data)} 曲 -> {train_jsonl}\")\n",
        "    print(f\"  Valid: {len(valid_data)} 曲 -> {valid_jsonl}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. 学習設定ファイルの作成 (Create Configuration)\n",
        "MusicGen-Largeのファインチューニング設定ファイル (`finetune.yaml`) を作成します。\n",
        "GPUメモリに合わせて `batch_size` を調整してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create-config"
      },
      "outputs": [],
      "source": [
        "# @title 設定ファイル (finetune.yaml) の作成\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "# リジューム機能: 既存のチェックポイントがあるか確認\n",
        "# 最新のチェックポイントを探すロジック\n",
        "checkpoint_path = \"//pretrained/facebook/musicgen-large\"\n",
        "if os.path.exists(output_dir):\n",
        "    checkpoints = [f for f in os.listdir(output_dir) if f.endswith('.th')]\n",
        "    if checkpoints:\n",
        "        # checkpoint.th (最新) があればそれを使う\n",
        "        if 'checkpoint.th' in checkpoints:\n",
        "             checkpoint_path = os.path.join(output_dir, 'checkpoint.th')\n",
        "             print(f\"既存のチェックポイントから再開します: {checkpoint_path}\")\n",
        "        else:\n",
        "             print(\"チェックポイントファイルが見つかりません。新規学習を開始します。\")\n",
        "    else:\n",
        "        print(\"保存ディレクトリが空です。新規学習を開始します。\")\n",
        "\n",
        "config = {\n",
        "    \"continue_from\": checkpoint_path,\n",
        "    \"defaults\": [\n",
        "        {\"dset\": \"audio/default\"},\n",
        "        {\"solver\": \"musicgen/musicgen_base_32khz\"},\n",
        "        \"_self_\"\n",
        "    ],\n",
        "    \"dset\": {\n",
        "        \"train\": {\"paths\": [str(train_jsonl)]},\n",
        "        \"valid\": {\"paths\": [str(valid_jsonl)]},\n",
        "        \"evaluate\": {\"paths\": [str(valid_jsonl)]},\n",
        "        \"processor\": {\"sample_rate\": 32000, \"channels\": 1} # モノラル想定\n",
        "    },\n",
        "    \"solver\": {\n",
        "        \"max_epochs\": 10,  # 必要に応じて増減\n",
        "        \"max_gen_epochs\": 2, # 生成テストを行う頻度\n",
        "        \"batch_size\": 4,   # A100なら4-8, V100なら2-4, T4なら1 (OOMの場合は減らす)\n",
        "        \"gradient_accumulation_steps\": 4, # バッチサイズが小さい場合は増やす\n",
        "        \"audio_box\": {\n",
        "            \"sample_rate\": 32000,\n",
        "            \"segment_duration\": 30.0\n",
        "        }\n",
        "    },\n",
        "    \"checkpoint\": {\n",
        "        \"save_last\": True,\n",
        "        \"save_every\": 1,\n",
        "        \"keep_last\": 5,\n",
        "        \"save_folder\": output_dir # Driveに保存\n",
        "    },\n",
        "    \"logging\": {\n",
        "        \"log_tensorboard\": True,\n",
        "        \"log_wandb\": True,\n",
        "        \"wandb_project\": \"musicgen-finetune\"\n",
        "    },\n",
        "    # Largeモデル用の最適化設定 (FSDPなど)\n",
        "    \"fsdp\": {\n",
        "        \"use\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "# YAMLとして保存\n",
        "config_path = '/content/audiocraft/config/solver/musicgen/musicgen_finetune.yaml'\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(f\"設定ファイルを保存しました: {config_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 学習の実行 (Run Training)\n",
        "`dora` コマンドを使用して学習を開始します。\n",
        "※学習には数時間〜数日かかる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-training"
      },
      "outputs": [],
      "source": [
        "# @title 学習の開始\n",
        "import wandb\n",
        "\n",
        "# WANDBログイン (APIキーが必要です)\n",
        "wandb.login()\n",
        "\n",
        "# dora run コマンドで学習を実行\n",
        "# solverに先ほど作成した設定を指定します\n",
        "!dora run solver=musicgen/musicgen_finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. 生成・推論 (Inference / Generation)\n",
        "学習したモデル（チェックポイント）をロードして、テキストから楽曲を生成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inference"
      },
      "outputs": [],
      "source": [
        "# @title 学習済みモデルでの楽曲生成\n",
        "from audiocraft.models import MusicGen\n",
        "from audiocraft.data.audio import audio_write\n",
        "import torch\n",
        "\n",
        "# 最新のチェックポイントを自動的に探す、またはパスを直接指定\n",
        "# 例: model_path = \"/content/drive/MyDrive/MusicGen_Checkpoints/checkpoint.th\"\n",
        "# ここでは学習直後と仮定して、保存先ディレクトリを指定してロードする方法を示します\n",
        "# 注意: 実際のチェックポイントファイルパスを確認して指定してください\n",
        "\n",
        "# 学習が完了していない場合やテスト用に、ここではベースモデルをロードする例を書きますが、\n",
        "# ファインチューニング後は以下のようにパスを指定してロードします：\n",
        "# model = MusicGen.get_pretrained(output_dir) # 保存フォルダを指定\n",
        "\n",
        "print(\"モデルをロード中...\")\n",
        "# デモ用にfacebookのモデルをロードする場合:\n",
        "# model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "\n",
        "# ファインチューニングしたモデルをロードする場合 (パスは適宜修正):\n",
        "# doraのログに出力されたチェックポイントパス(.thファイル)を指定するのが確実です\n",
        "# model = MusicGen.get_pretrained('/content/drive/MyDrive/MusicGen_Checkpoints/<sig>/checkpoint.th')\n",
        "\n",
        "# --- 以下、生成コード ---\n",
        "# モデルのパラメータ設定\n",
        "model.set_generation_params(\n",
        "    use_sampling=True,\n",
        "    top_k=250,\n",
        "    duration=30  # 生成する秒数\n",
        ")\n",
        "\n",
        "# プロンプトの設定\n",
        "descriptions = [\n",
        "    \"A fast paced rock song with heavy guitar riffs\",\n",
        "    \"Lo-fi hip hop beat with a chill vibe\",\n",
        "    \"Orchestral symphony with dramatic strings\"\n",
        "]\n",
        "\n",
        "print(\"生成を開始します...\")\n",
        "wav = model.generate(descriptions)  # 生成実行\n",
        "\n",
        "# 音声の保存と再生\n",
        "for idx, one_wav in enumerate(wav):\n",
        "    # 音声を保存\n",
        "    filename = f\"generated_{idx}\"\n",
        "    audio_write(filename, one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "    print(f\"保存しました: {filename}.wav\")\n",
        "    \n",
        "    # Colab上で再生するためのウィジェット表示\n",
        "    from IPython.display import Audio, display\n",
        "    display(Audio(filename + \".wav\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
