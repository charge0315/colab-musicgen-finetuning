{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "942b32ed",
      "metadata": {
        "id": "942b32ed"
      },
      "source": [
        "# MusicGen-Large ã‚’ A100 (80GB) 1å°ã§ LoRA + DeepSpeed ã§å­¦ç¿’ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
        "\n",
        "**ç›®çš„**: 18,000 æ›² Ã— 30 ç§’ãƒãƒ£ãƒ³ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã„ã€MusicGen-Large ã« LoRA ã‚’é©ç”¨ã—ã¦å­¦ç¿’ã™ã‚‹ã€‚WandB ãƒ­ã‚®ãƒ³ã‚°ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã«ã‚ˆã‚‹å†é–‹ï¼ˆresumeï¼‰æ©Ÿèƒ½ä»˜ãã€‚ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼ˆEnCodecï¼‰ã‚’ä¸¦åˆ—ã«è¡Œã„ã€æœ€åˆã® 100 ãƒ•ã‚¡ã‚¤ãƒ«ã§é€Ÿåº¦ã‚’è¨ˆæ¸¬ã—ã¦ç·æ™‚é–“ã‚’æ¨å®šã™ã‚‹ã‚»ãƒ«ã‚’å«ã‚€ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ äº‹å‰æº–å‚™\n",
        "\n",
        "1. **Google Colabã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ **: GPU (A100æ¨å¥¨) ã‚’é¸æŠ\n",
        "2. **ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®è¨­å®š**: Colabã®ã€ŒğŸ”‘ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ä»¥ä¸‹ã‚’è¨­å®š\n",
        "   - `WANDB_API_KEY`: WandB APIã‚­ãƒ¼ï¼ˆhttps://wandb.ai/settings ã‹ã‚‰å–å¾—ï¼‰\n",
        "   - `HF_TOKEN`: Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆhttps://huggingface.co/settings/tokens ã‹ã‚‰å–å¾—ï¼‰\n",
        "3. **Google Drive**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆtar.gz ã¾ãŸã¯å±•é–‹æ¸ˆã¿ï¼‰ã‚’é…ç½®\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ ä½¿ã„æ–¹\n",
        "\n",
        "1. ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ\n",
        "2. ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰è‡ªå‹•çš„ã«APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "3. WandBã§å­¦ç¿’é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–: https://wandb.ai/\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc89e0d6",
      "metadata": {
        "id": "cc89e0d6"
      },
      "source": [
        "## ã‚»ãƒ« 1 â€” ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8efee78c",
      "metadata": {
        "id": "8efee78c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e983d7d6-17cf-41bb-b26e-3c80400029dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torch==2.9.0+cu126 in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchaudio==2.9.0+cu126 in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.8.1+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0+cu126) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0+cu126) (3.0.3)\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "Collecting git+https://github.com/facebookresearch/audiocraft.git@main\n",
            "  Cloning https://github.com/facebookresearch/audiocraft.git (to revision main) to /tmp/pip-req-build-lz8m07z4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/audiocraft.git /tmp/pip-req-build-lz8m07z4\n",
            "  Resolved https://github.com/facebookresearch/audiocraft.git to commit 896ec7c47f5e5d1e5aa1e4b260c4405328bf009d\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.12/dist-packages (0.18.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: loralib in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed) (0.8.1)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.12/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.1.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.12.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.9.0+cu126)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from deepspeed) (13.580.82)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->deepspeed) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->deepspeed) (3.0.3)\n",
            "ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
          ]
        }
      ],
      "source": [
        "# å®Ÿè¡Œå‰ã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã® GPU ã‚’ç¢ºèªã€‚CUDA ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã‚ã›ã¦ torch ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚\n",
        "# ä¾‹ï¼šCUDA 11.8 / PyTorch 2.1 ã®å ´åˆ\n",
        "!pip install --upgrade pip\n",
        "!pip install torch==2.9.0+cu126 torchaudio==2.9.0+cu126 torchcodec --extra-index-url https://download.pytorch.org/whl/cu126\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# audiocraft (MusicGen ã‚’å«ã‚€) å…¬å¼ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰\n",
        "# audiocraftãŒtorch==2.1.0ã‚’è¦æ±‚ã—ã€ç¾åœ¨ã®ç’°å¢ƒã®torch==2.9.0ã¨ç«¶åˆã™ã‚‹ãŸã‚ã€\n",
        "# --no-deps ã¨ --no-build-isolation ã‚’ä½¿ã£ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è©¦ã¿ã‚‹\n",
        "# --no-deps: audiocraftã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—\n",
        "# --no-build-isolation: ãƒ“ãƒ«ãƒ‰æ™‚ã«åˆ†é›¢ã•ã‚ŒãŸç’°å¢ƒã‚’ä½¿ã‚ãšã€æ—¢å­˜ã®ç’°å¢ƒã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’åˆ©ç”¨\n",
        "!pip install git+https://github.com/facebookresearch/audiocraft.git@main --no-deps --no-build-isolation\n",
        "\n",
        "# LoRA / DeepSpeed / WandB ãªã©\n",
        "!pip install deepspeed wandb soundfile librosa loralib tqdm\n",
        "\n",
        "print(\"ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c3750b6",
      "metadata": {
        "id": "8c3750b6"
      },
      "source": [
        "## ã‚»ãƒ« 2 â€” Drive ãƒã‚¦ãƒ³ãƒˆã¨ãƒ‡ãƒ¼ã‚¿å±•é–‹ï¼ˆå¿…è¦ãªã‚‰ unzipï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c92107ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c92107ff",
        "outputId": "fb0d5da9-e4e6-4f51-fb46-bc1453608b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âš ï¸ ã‚¨ãƒ©ãƒ¼: zipãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: /content/drive/MyDrive/Archive_Wavs/archive_batch_001.zip\n",
            "ğŸ“„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­: /content/drive/MyDrive/Archive_Wavs/metadata.jsonl\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount(\"/content/drive\",force_remount=True)\n",
        "\n",
        "# --- è¨­å®š ---\n",
        "DRIVE_DATASET_ZIP = \"/content/drive/MyDrive/Archive_Wavs/archive_batch_0001.zip\"\n",
        "METADATA_DRIVE_PATH = \"/content/drive/MyDrive/Archive_Wavs/metadata.jsonl\"\n",
        "DATA_DIR = \"/content/drive/MyDrive/MusicGen_Dataet/temp_wav_chanks\"\n",
        "# ------------\n",
        "\n",
        "# DATA_DIR ã‚’äº‹å‰ã«ä½œæˆã™ã‚‹\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å±•é–‹\n",
        "if os.path.exists(DRIVE_DATASET_ZIP):\n",
        "    print(f\"ğŸ“¦ {DRIVE_DATASET_ZIP} ã‚’å±•é–‹ã—ã¾ã™...\")\n",
        "    # os.makedirs(DATA_DIR, exist_ok=True) # ã“ã“ã§ã‚‚è‰¯ã„ãŒã€metadataå‡¦ç†å‰ã«ç¢ºå®Ÿã«å­˜åœ¨ã™ã‚‹ã‚ˆã†ã«ç§»å‹•\n",
        "    # if os.path.exists(DATA_DIR): # DATA_DIRã‚’äº‹å‰ã«ä½œæˆã—ãŸã®ã§ä¸è¦\n",
        "    #     !rm -rf {DATA_DIR} # ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã¯æ‰‹å‹•ã§å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã€æ³¨æ„\n",
        "\n",
        "    # -d ã§å±•é–‹å…ˆã‚’æŒ‡å®š, -q ã§ãƒ­ã‚°æŠ‘åˆ¶\n",
        "    !unzip -q {DRIVE_DATASET_ZIP} -d {DATA_DIR}\n",
        "    print(\"âœ“ å±•é–‹å®Œäº†\")\n",
        "else:\n",
        "    print(f\"âš ï¸ ã‚¨ãƒ©ãƒ¼: zipãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DRIVE_DATASET_ZIP}\")\n",
        "\n",
        "# 2. metadata.jsonl ã®å‡¦ç†ã¨ãƒ‘ã‚¹æ›¸ãæ›ãˆ\n",
        "dest_metadata_path = os.path.join(DATA_DIR, \"metadata.jsonl\")\n",
        "\n",
        "if os.path.exists(METADATA_DRIVE_PATH):\n",
        "    print(f\"ğŸ“„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­: {METADATA_DRIVE_PATH}\")\n",
        "\n",
        "    new_lines = []\n",
        "    processed_count = 0\n",
        "\n",
        "    with open(METADATA_DRIVE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                entry = json.loads(line)\n",
        "                original_path = entry.get(\"path\", \"\")\n",
        "                filename = os.path.basename(original_path)\n",
        "\n",
        "                # å±•é–‹å…ˆã§ã®å®Ÿéš›ã®ãƒ‘ã‚¹ã‚’æ¢ã™\n",
        "                # (ãƒ•ãƒ©ãƒƒãƒˆã«å±•é–‹ã•ã‚Œã¦ã„ã‚‹ã‹ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ãŒã‚ã‚‹ã‹ä¸æ˜ãªãŸã‚æ¤œç´¢)\n",
        "                potential_path = os.path.join(DATA_DIR, filename)\n",
        "\n",
        "                found_path = None\n",
        "                if os.path.exists(potential_path):\n",
        "                    found_path = potential_path\n",
        "                else:\n",
        "                    # ç›´ä¸‹ã«ãªã„å ´åˆã¯å†å¸°çš„ã«æ¢ã™\n",
        "                    # (ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãŒå¤šã„å ´åˆã¯æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™)\n",
        "                    found = list(Path(DATA_DIR).rglob(filename))\n",
        "                    if found:\n",
        "                        found_path = str(found[0])\n",
        "\n",
        "                if found_path:\n",
        "                    entry[\"path\"] = found_path\n",
        "                    new_lines.append(json.dumps(entry))\n",
        "                    processed_count += 1\n",
        "                else:\n",
        "                    # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã‚‚ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã¯æ®‹ã™ãŒãƒ‘ã‚¹ã¯æ¨å®šå€¤ã‚’ã‚»ãƒƒãƒˆ\n",
        "                    entry[\"path\"] = potential_path\n",
        "                    new_lines.append(json.dumps(entry))\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "    # æ–°ã—ã„metadata.jsonlã‚’ä¿å­˜\n",
        "    with open(dest_metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(new_lines))\n",
        "\n",
        "    print(f\"âœ“ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹ã‚’æ›¸ãæ›ãˆã¦ä¿å­˜ã—ã¾ã—ãŸ: {dest_metadata_path}\")\n",
        "    print(f\"  å‡¦ç†ä»¶æ•°: {processed_count} ä»¶\")\n",
        "\n",
        "    # ç¢ºèªè¡¨ç¤º\n",
        "    print(\"\\næ›¸ãæ›ãˆå¾Œã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¾‹ (æœ€åˆã®3ä»¶):\")\n",
        "    !head -n 3 {dest_metadata_path}\n",
        "\n",
        "else:\n",
        "    print(f\"âš ï¸ ã‚¨ãƒ©ãƒ¼: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {METADATA_DRIVE_PATH}\")\n",
        "\n",
        "print(\"\\ndata dir =\", DATA_DIR)\n",
        "!ls -l {DATA_DIR} | head -n 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58dccc64",
      "metadata": {
        "id": "58dccc64"
      },
      "source": [
        "## ã‚»ãƒ« 2.5 â€” WandBã¨Hugging Faceã®èªè¨¼è¨­å®š\n",
        "\n",
        "ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9ba5cf67",
      "metadata": {
        "id": "9ba5cf67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b7ed98-ae53-402f-f56b-ed9cc02f0b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ WandBã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ\n",
            "âœ“ Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ã¾ã—ãŸ\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "try:\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "    # WandBãƒ­ã‚°ã‚¤ãƒ³\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "    print(\"âœ“ WandBã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ\")\n",
        "\n",
        "    # Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®š\n",
        "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "    print(\"âœ“ Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ã¾ã—ãŸ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "    print(\"Colabã®ã€Œã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:\")\n",
        "    print(\"  - WANDB_API_KEY: WandBã®APIã‚­ãƒ¼\")\n",
        "    print(\"  - HF_TOKEN: Hugging Faceã®APIãƒˆãƒ¼ã‚¯ãƒ³\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571cf84f",
      "metadata": {
        "id": "571cf84f"
      },
      "source": [
        "## ã‚»ãƒ« 2.6 â€” ğŸ§ª å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ\n",
        "\n",
        "æœ¬æ ¼çš„ãªå­¦ç¿’ã‚’å§‹ã‚ã‚‹å‰ã«ã€5ã€œ10å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã§å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a607db1e",
      "metadata": {
        "id": "a607db1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "6247a933-a785-47c1-9aae-675a36d7ec4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸ§ª å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰\n",
            "============================================================\n",
            "ã‚µãƒ³ãƒ—ãƒ«æ•°: 5\n",
            "ã‚¨ãƒãƒƒã‚¯æ•°: 2\n",
            "\n",
            "ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç¢ºèª\n",
            "âš ï¸ è­¦å‘Š: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«æœ‰åŠ¹ãªãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€/content/MyDrive/MusicGen_Dataet/wav_chankså†…ã®.wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¾ã™ã€‚\n",
            "âš ï¸ è­¦å‘Š: åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒ0å€‹ã—ã‹ã‚ã‚Šã¾ã›ã‚“\n",
            "âœ“ 0å€‹ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ\n",
            "\n",
            "ğŸµ ã‚¹ãƒ†ãƒƒãƒ—2: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3105655880.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mcompression_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ“ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå®Œäº† (å¹³å‡: {sum(tokenize_times)/len(tokenize_times):.2f}ç§’/ãƒ•ã‚¡ã‚¤ãƒ«)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchaudio\n",
        "from audiocraft.models import CompressionModel, MusicGen\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import loralib as lora\n",
        "import torch.nn as nn\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆè¨­å®š\n",
        "TEST_MODE = True  # Falseã«ã™ã‚‹ã¨æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰\n",
        "NUM_TEST_SAMPLES = 5  # ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°\n",
        "TEST_EPOCHS = 2  # ãƒ†ã‚¹ãƒˆã‚¨ãƒãƒƒã‚¯æ•°\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ§ª å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ã‚µãƒ³ãƒ—ãƒ«æ•°: {NUM_TEST_SAMPLES}\")\n",
        "print(f\"ã‚¨ãƒãƒƒã‚¯æ•°: {TEST_EPOCHS}\")\n",
        "print()\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "TEST_TOKEN_DIR = '/content/test_tokens'\n",
        "os.makedirs(TEST_TOKEN_DIR, exist_ok=True)\n",
        "\n",
        "# 1. ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
        "print(\"ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç¢ºèª\")\n",
        "meta_path = os.path.join(DATA_DIR, 'metadata.jsonl')\n",
        "paths = []\n",
        "\n",
        "if os.path.exists(meta_path):\n",
        "    with open(meta_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                j = json.loads(line)\n",
        "                p = j['path']\n",
        "                # DATA_DIRãŒ/content/datasetã®å ´åˆã€ãƒ‘ã‚¹ãŒæ­£ã—ããªã‚‹ã‚ˆã†ã«èª¿æ•´\n",
        "                if not os.path.isabs(p) or not p.startswith(DATA_DIR):\n",
        "                    filename = os.path.basename(p)\n",
        "                    p = os.path.join(DATA_DIR, filename)\n",
        "                if os.path.exists(p):\n",
        "                    paths.append(p)\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "else:\n",
        "    paths = list(Path(DATA_DIR).rglob('*.wav'))\n",
        "    paths = [str(p) for p in paths]\n",
        "\n",
        "# DATA_DIRå†…ã®.wavãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ä»£æ›¿ç­–\n",
        "if not paths:\n",
        "    print(f\"âš ï¸ è­¦å‘Š: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«æœ‰åŠ¹ãªãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€{DATA_DIR}å†…ã®.wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¾ã™ã€‚\")\n",
        "    paths = list(Path(DATA_DIR).rglob('*.wav'))\n",
        "    paths = [str(p) for p in paths]\n",
        "\n",
        "if len(paths) < NUM_TEST_SAMPLES:\n",
        "    print(f\"âš ï¸ è­¦å‘Š: åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒ{len(paths)}å€‹ã—ã‹ã‚ã‚Šã¾ã›ã‚“\")\n",
        "    NUM_TEST_SAMPLES = len(paths)\n",
        "\n",
        "test_paths = paths[:NUM_TEST_SAMPLES]\n",
        "print(f\"âœ“ {len(test_paths)}å€‹ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ\")\n",
        "for i, p in enumerate(test_paths):\n",
        "    print(f\"  {i+1}. {Path(p).name}\")\n",
        "print()\n",
        "\n",
        "# 2. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸµ ã‚¹ãƒ†ãƒƒãƒ—2: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ\")\n",
        "compression_model = CompressionModel.get_pretrained('facebook/encodec_32khz')\n",
        "compression_model.to('cuda')\n",
        "compression_model.eval()\n",
        "\n",
        "tokenize_times = []\n",
        "for i, p in enumerate(test_paths):\n",
        "    try:\n",
        "        t0 = time.time()\n",
        "        wav, sr = torchaudio.load(p)\n",
        "\n",
        "        if sr != 32000:\n",
        "            resampler = torchaudio.transforms.Resample(sr, 32000)\n",
        "            wav = resampler(wav)\n",
        "\n",
        "        if wav.shape[0] > 1:\n",
        "            wav = wav.mean(dim=0, keepdim=True)\n",
        "\n",
        "        wav = wav.unsqueeze(0).to('cuda')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            encoded_frames = compression_model.encode(wav)\n",
        "            tokens = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)\n",
        "\n",
        "        outp = os.path.join(TEST_TOKEN_DIR, Path(p).stem + '.pt')\n",
        "        torch.save({'tokens': tokens.cpu(), 'path': p}, outp)\n",
        "\n",
        "        dt = time.time() - t0\n",
        "        tokenize_times.append(dt)\n",
        "        print(f\"  âœ“ ãƒ•ã‚¡ã‚¤ãƒ«{i+1}: {dt:.2f}ç§’ - ãƒˆãƒ¼ã‚¯ãƒ³å½¢çŠ¶: {tokens.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âœ— ãƒ•ã‚¡ã‚¤ãƒ«{i+1}ã§ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        raise\n",
        "\n",
        "del compression_model\n",
        "torch.cuda.empty_cache()\n",
        "print(f\"âœ“ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå®Œäº† (å¹³å‡: {sum(tokenize_times)/len(tokenize_times):.2f}ç§’/ãƒ•ã‚¡ã‚¤ãƒ«)\")\n",
        "print()\n",
        "\n",
        "# 3. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ“¦ ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "\n",
        "class TestTokenDataset(Dataset):\n",
        "    def __init__(self, token_dir, max_length=1500):\n",
        "        self.files = sorted(list(Path(token_dir).glob('*.pt')))\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.load(self.files[idx])\n",
        "        tokens = data['tokens']\n",
        "        if tokens.dim() == 3:\n",
        "            tokens = tokens.squeeze(0)\n",
        "\n",
        "        seq_len = tokens.shape[-1]\n",
        "        if seq_len > self.max_length:\n",
        "            tokens = tokens[:, :self.max_length]\n",
        "        elif seq_len < self.max_length:\n",
        "            pad_length = self.max_length - seq_len\n",
        "            tokens = torch.nn.functional.pad(tokens, (0, pad_length), value=0)\n",
        "        return tokens\n",
        "\n",
        "test_dataset = TestTokenDataset(TEST_TOKEN_DIR)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "print(f\"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ: {len(test_dataset)}ã‚µãƒ³ãƒ—ãƒ«\")\n",
        "\n",
        "# ãƒãƒƒãƒã®ãƒ†ã‚¹ãƒˆ\n",
        "for batch in test_loader:\n",
        "    print(f\"âœ“ ãƒãƒƒãƒå½¢çŠ¶: {batch.shape}\")\n",
        "    break\n",
        "print()\n",
        "\n",
        "# 4. ãƒ¢ãƒ‡ãƒ«ã¨LoRAã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¨LoRAé©ç”¨ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "print(\"âœ“ MusicGen-Large ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
        "\n",
        "def apply_lora_to_linear(module, r=8, lora_alpha=32, lora_dropout=0.1, parent_name='', count=[0]):\n",
        "    for name, child in list(module.named_children()):\n",
        "        full_name = f\"{parent_name}.{name}\" if parent_name else name\n",
        "        if isinstance(child, nn.Linear) and count[0] < 3:  # ãƒ†ã‚¹ãƒˆã§ã¯æœ€åˆã®3å±¤ã®ã¿\n",
        "            in_features = child.in_features\n",
        "            out_features = child.out_features\n",
        "            bias = child.bias is not None\n",
        "\n",
        "            lora_linear = lora.Linear(\n",
        "                in_features, out_features, r=r,\n",
        "                lora_alpha=lora_alpha, lora_dropout=lora_dropout, bias=bias\n",
        "            )\n",
        "            lora_linear.weight.data = child.weight.data.clone()\n",
        "            if bias:\n",
        "                lora_linear.bias.data = child.bias.data.clone()\n",
        "\n",
        "            setattr(module, name, lora_linear)\n",
        "            count[0] += 1\n",
        "            print(f\"  âœ“ LoRAé©ç”¨ {count[0]}: {full_name}\")\n",
        "        else:\n",
        "            apply_lora_to_linear(child, r=r, lora_alpha=lora_alpha,\n",
        "                               lora_dropout=lora_dropout, parent_name=full_name, count=count)\n",
        "\n",
        "apply_lora_to_linear(model.lm, r=8)\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "for name, p in model.named_parameters():\n",
        "    if 'lora_' in name:\n",
        "        p.requires_grad = True\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"âœ“ å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {trainable:,} / {total:,} ({100*trainable/total:.4f}%)\")\n",
        "print()\n",
        "\n",
        "# 5. å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ‹ï¸ ã‚¹ãƒ†ãƒƒãƒ—5: å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®ãƒ†ã‚¹ãƒˆ\")\n",
        "model = model.to('cuda')\n",
        "optimizer = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4, weight_decay=0.01\n",
        ")\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(TEST_EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_idx, tokens in enumerate(test_loader):\n",
        "        tokens = tokens.to('cuda')\n",
        "\n",
        "        # ç°¡æ˜“æå¤±è¨ˆç®—\n",
        "        outputs = model.lm.forward(tokens)\n",
        "        loss = criterion(outputs, tokens.float())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        print(f\"  Epoch {epoch+1}/{TEST_EPOCHS}, Batch {batch_idx+1}: loss={loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = epoch_loss / len(test_loader)\n",
        "    print(f\"âœ“ Epoch {epoch+1} å®Œäº†: å¹³å‡æå¤±={avg_loss:.4f}\")\n",
        "print()\n",
        "\n",
        "# 6. ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ\n",
        "print(\"ğŸ¶ ã‚¹ãƒ†ãƒƒãƒ—6: æ¥½æ›²ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ\")\n",
        "model.eval()\n",
        "model.set_generation_params(\n",
        "    use_sampling=True,\n",
        "    top_k=250,\n",
        "    duration=5  # ãƒ†ã‚¹ãƒˆã§ã¯5ç§’\n",
        ")\n",
        "\n",
        "test_prompts = [\"A short piano melody\"]\n",
        "print(f\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {test_prompts[0]}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    wav = model.generate(test_prompts)\n",
        "\n",
        "print(f\"âœ“ ç”Ÿæˆå®Œäº†: å½¢çŠ¶={wav[0].shape}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ={model.sample_rate}\")\n",
        "\n",
        "# éŸ³å£°ã‚’ä¿å­˜\n",
        "from audiocraft.data.audio import audio_write\n",
        "test_output = '/content/test_generation'\n",
        "audio_write(test_output, wav[0].cpu(), model.sample_rate, strategy=\"loudness\")\n",
        "print(f\"âœ“ ãƒ†ã‚¹ãƒˆéŸ³å£°ã‚’ä¿å­˜: {test_output}.wav\")\n",
        "\n",
        "# IPythonè¡¨ç¤º\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(test_output + \".wav\", rate=model.sample_rate))\n",
        "print()\n",
        "\n",
        "# ãƒ¡ãƒ¢ãƒªè§£æ”¾\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†ï¼\")\n",
        "print(\"=\" * 60)\n",
        "print(\"å•é¡ŒãŒãªã‘ã‚Œã°ã€æ¬¡ã®ã‚»ãƒ«ã‹ã‚‰æœ¬æ ¼çš„ãªå‡¦ç†ã‚’é–‹å§‹ã§ãã¾ã™ã€‚\")\n",
        "print()\n",
        "print(\"ğŸ“ ç¢ºèªäº‹é …:\")\n",
        "print(\"  âœ“ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\")\n",
        "print(\"  âœ“ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå‡¦ç†\")\n",
        "print(\"  âœ“ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€\")\n",
        "print(\"  âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¨LoRAé©ç”¨\")\n",
        "print(\"  âœ“ å­¦ç¿’ãƒ«ãƒ¼ãƒ—\")\n",
        "print(\"  âœ“ æ¥½æ›²ç”Ÿæˆ\")\n",
        "print()\n",
        "print(\"âš ï¸ æ³¨æ„: æœ¬ç•ªå®Ÿè¡Œå‰ã« TEST_MODE = False ã«è¨­å®šã—ã¦ãã ã•ã„\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19d0c028",
      "metadata": {
        "id": "19d0c028"
      },
      "source": [
        "## ã‚»ãƒ« 3 â€” å…ˆé ­ 100 ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºé€Ÿåº¦è¨ˆæ¸¬ï¼ˆEnCodec ã‚’æƒ³å®šï¼‰\n",
        "\n",
        "- ç›®çš„ï¼šå®Ÿæ¸¬ã—ãŸãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºé€Ÿåº¦ã‹ã‚‰å…¨ä½“ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºæ™‚é–“ã‚’è¦‹ç©ã‚‚ã‚‹\n",
        "- å‡ºåŠ›ï¼š1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Šã®å¹³å‡ç§’æ•°ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºãƒ»ä¿å­˜ï¼‰ã€ç·è¦‹ç©ï¼ˆæ™‚é–“ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827fb6b3",
      "metadata": {
        "id": "827fb6b3"
      },
      "outputs": [],
      "source": [
        "import time, json, os, glob\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchaudio\n",
        "import wandb\n",
        "\n",
        "# audiocraft ã® EnCodec ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "from audiocraft.models import CompressionModel\n",
        "\n",
        "# WandBå®Ÿé¨“ã‚’é–‹å§‹ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå‡¦ç†ã®è¿½è·¡ç”¨ï¼‰\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "    if not wandb.api.api_key:\n",
        "        wandb.login(key=WANDB_API_KEY)\n",
        "\n",
        "    wandb.init(\n",
        "        project='musicgen-lora-finetune',\n",
        "        name=f'tokenization_{time.strftime(\"%Y%m%d_%H%M%S\")}',\n",
        "        job_type='preprocessing',\n",
        "        tags=['tokenization', 'encodec']\n",
        "    )\n",
        "    use_wandb = True\n",
        "    print('âœ“ WandBãƒ­ã‚®ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼‰')\n",
        "except:\n",
        "    use_wandb = False\n",
        "    print('âš ï¸ WandBç„¡ã—ã§ç¶šè¡Œ')\n",
        "\n",
        "# è¨­å®š\n",
        "meta_path = os.path.join(DATA_DIR, 'metadata.jsonl')\n",
        "TOKEN_DIR = os.path.join(DATA_DIR, 'tokens')\n",
        "os.makedirs(TOKEN_DIR, exist_ok=True)\n",
        "\n",
        "# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¹ã‚’èª­ã¿è¾¼ã‚€\n",
        "paths = []\n",
        "if os.path.exists(meta_path):\n",
        "    with open(meta_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            j = json.loads(line)\n",
        "            p = j['path']\n",
        "            if not os.path.isabs(p):\n",
        "                p = os.path.join(DATA_DIR, p)\n",
        "            paths.append(p)\n",
        "else:\n",
        "    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã€wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥æ¢ã™\n",
        "    paths = list(Path(DATA_DIR).rglob('*.wav'))\n",
        "    paths = [str(p) for p in paths]\n",
        "\n",
        "sample_paths = paths[:100] if len(paths) >= 100 else paths\n",
        "print('è¨ˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«æ•°:', len(sample_paths))\n",
        "print('ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°:', len(paths))\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.config.update({\n",
        "        'total_files': len(paths),\n",
        "        'sample_files': len(sample_paths),\n",
        "        'token_dir': TOKEN_DIR,\n",
        "    })\n",
        "\n",
        "# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆfacebook/encodec_32khz ã‚’ä½¿ç”¨ï¼‰\n",
        "print('EnCodecãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "compression_model = CompressionModel.get_pretrained('facebook/encodec_32khz')\n",
        "compression_model.to('cuda')\n",
        "compression_model.eval()\n",
        "\n",
        "times = []\n",
        "for i, p in enumerate(sample_paths):\n",
        "    try:\n",
        "        t0 = time.time()\n",
        "\n",
        "        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "        wav, sr = torchaudio.load(p)\n",
        "\n",
        "        # 32kHzã«ãƒªã‚µãƒ³ãƒ—ãƒ«ï¼ˆå¿…è¦ãªå ´åˆï¼‰\n",
        "        if sr != 32000:\n",
        "            resampler = torchaudio.transforms.Resample(sr, 32000)\n",
        "            wav = resampler(wav)\n",
        "\n",
        "        # ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›\n",
        "        if wav.shape[0] > 1:\n",
        "            wav = wav.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # GPUã«è»¢é€\n",
        "        wav = wav.unsqueeze(0).to('cuda')  # [1, 1, T]\n",
        "\n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\n",
        "        with torch.no_grad():\n",
        "            encoded_frames = compression_model.encode(wav)\n",
        "            tokens = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)  # [B, K, T]\n",
        "\n",
        "        # ä¿å­˜\n",
        "        outp = os.path.join(TOKEN_DIR, Path(p).stem + '.pt')\n",
        "        torch.save({'tokens': tokens.cpu(), 'path': p}, outp)\n",
        "\n",
        "        dt = time.time() - t0\n",
        "        times.append(dt)\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            avg_time = sum(times)/(i+1)\n",
        "            print(f'processed {i+1}/{len(sample_paths)} avg {avg_time:.3f}s/file')\n",
        "\n",
        "            # WandBã«ãƒ­ã‚°\n",
        "            if use_wandb:\n",
        "                wandb.log({\n",
        "                    'tokenize_sample/processed': i+1,\n",
        "                    'tokenize_sample/avg_time_per_file': avg_time,\n",
        "                    'tokenize_sample/progress': (i+1) / len(sample_paths),\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f'Error processing {p}: {e}')\n",
        "        continue\n",
        "\n",
        "if times:\n",
        "    avg = sum(times) / len(times)\n",
        "    total_seconds = avg * len(paths)\n",
        "    estimated_hours = total_seconds / 3600\n",
        "\n",
        "    print('\\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºæ™‚é–“: {:.3f} ç§’/ãƒ•ã‚¡ã‚¤ãƒ«'.format(avg))\n",
        "    print('æ¨å®šå…¨ä½“ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºæ™‚é–“: {:.2f} æ™‚é–“ï¼ˆ= {:.0f} ç§’ï¼‰'.format(estimated_hours, total_seconds))\n",
        "\n",
        "    # WandBã«çµ±è¨ˆã‚’è¨˜éŒ²\n",
        "    if use_wandb:\n",
        "        wandb.log({\n",
        "            'tokenize_sample/avg_time_per_file': avg,\n",
        "            'tokenize_sample/estimated_total_hours': estimated_hours,\n",
        "            'tokenize_sample/estimated_total_seconds': total_seconds,\n",
        "            'tokenize_sample/sample_size': len(sample_paths),\n",
        "            'tokenize_sample/total_dataset_size': len(paths),\n",
        "        })\n",
        "        wandb.finish()\n",
        "else:\n",
        "    print('ã‚¨ãƒ©ãƒ¼: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸã€‚')\n",
        "\n",
        "# ãƒ¡ãƒ¢ãƒªè§£æ”¾\n",
        "del compression_model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ff8c941",
      "metadata": {
        "id": "2ff8c941"
      },
      "source": [
        "## ã‚»ãƒ« 4 â€” å…¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼ˆä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ©ç”¨ï¼‰\n",
        "\n",
        "- å…ˆé ­100ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœã§ `avg` ã‚’å–å¾—ã—ãŸã‚‰ã€ã“ã“ã§å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d113b10",
      "metadata": {
        "id": "8d113b10"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from audiocraft.models import CompressionModel\n",
        "import wandb\n",
        "\n",
        "# WandBå®Ÿé¨“ã‚’é–‹å§‹ï¼ˆå…¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå‡¦ç†ã®è¿½è·¡ç”¨ï¼‰\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "    if not wandb.api.api_key:\n",
        "        wandb.login(key=WANDB_API_KEY)\n",
        "\n",
        "    wandb.init(\n",
        "        project='musicgen-lora-finetune',\n",
        "        name=f'tokenization_full_{time.strftime(\"%Y%m%d_%H%M%S\")}',\n",
        "        job_type='preprocessing',\n",
        "        tags=['tokenization-full', 'encodec']\n",
        "    )\n",
        "    use_wandb = True\n",
        "    print('âœ“ WandBãƒ­ã‚®ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ï¼ˆå…¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼‰')\n",
        "except:\n",
        "    use_wandb = False\n",
        "    print('âš ï¸ WandBç„¡ã—ã§ç¶šè¡Œ')\n",
        "\n",
        "# EnCodecãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "print('EnCodecãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "compression_model = CompressionModel.get_pretrained('facebook/encodec_32khz')\n",
        "compression_model.to('cuda')\n",
        "compression_model.eval()\n",
        "\n",
        "# æ—¢ã«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºæ¸ˆã¿ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—\n",
        "existing_tokens = set([Path(f).stem for f in glob.glob(os.path.join(TOKEN_DIR, '*.pt'))])\n",
        "remaining_paths = [p for p in paths if Path(p).stem not in existing_tokens]\n",
        "\n",
        "print(f'æ®‹ã‚Šã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå¯¾è±¡: {len(remaining_paths)} ãƒ•ã‚¡ã‚¤ãƒ«')\n",
        "print(f'æ—¢ã«å®Œäº†: {len(existing_tokens)} ãƒ•ã‚¡ã‚¤ãƒ«')\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.config.update({\n",
        "        'total_files': len(paths),\n",
        "        'already_tokenized': len(existing_tokens),\n",
        "        'remaining_files': len(remaining_paths),\n",
        "    })\n",
        "\n",
        "success_count = 0\n",
        "fail_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for i, p in enumerate(tqdm(remaining_paths, desc='ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºä¸­')):\n",
        "    try:\n",
        "        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "        wav, sr = torchaudio.load(p)\n",
        "\n",
        "        # 32kHzã«ãƒªã‚µãƒ³ãƒ—ãƒ«ï¼ˆå¿…è¦ãªå ´åˆï¼‰\n",
        "        if sr != 32000:\n",
        "            resampler = torchaudio.transforms.Resample(sr, 32000)\n",
        "            wav = resampler(wav)\n",
        "\n",
        "        # ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›\n",
        "        if wav.shape[0] > 1:\n",
        "            wav = wav.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # GPUã«è»¢é€\n",
        "        wav = wav.unsqueeze(0).to('cuda')  # [1, 1, T]\n",
        "\n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\n",
        "        with torch.no_grad():\n",
        "            encoded_frames = compression_model.encode(wav)\n",
        "            tokens = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)\n",
        "\n",
        "        # ä¿å­˜\n",
        "        outp = os.path.join(TOKEN_DIR, Path(p).stem + '.pt')\n",
        "        torch.save({'tokens': tokens.cpu(), 'path': p}, outp)\n",
        "        success_count += 1\n",
        "\n",
        "        # å®šæœŸçš„ã«WandBã«ãƒ­ã‚°ï¼ˆ100ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ï¼‰\n",
        "        if use_wandb and (i + 1) % 100 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            avg_time = elapsed / (i + 1)\n",
        "            remaining_time = avg_time * (len(remaining_paths) - i - 1)\n",
        "\n",
        "            wandb.log({\n",
        "                'tokenize_full/processed': success_count,\n",
        "                'tokenize_full/failed': fail_count,\n",
        "                'tokenize_full/progress': (i + 1) / len(remaining_paths),\n",
        "                'tokenize_full/avg_time_per_file': avg_time,\n",
        "                'tokenize_full/estimated_remaining_hours': remaining_time / 3600,\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'\\nError processing {p}: {e}')\n",
        "        fail_count += 1\n",
        "        continue\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f'\\nå®Œäº†: {success_count} ä»¶æˆåŠŸ, {fail_count} ä»¶å¤±æ•—')\n",
        "print(f'ç·å‡¦ç†æ™‚é–“: {total_time/3600:.2f} æ™‚é–“')\n",
        "\n",
        "# æœ€çµ‚çµ±è¨ˆã‚’WandBã«è¨˜éŒ²\n",
        "if use_wandb:\n",
        "    wandb.log({\n",
        "        'tokenize_full/total_success': success_count,\n",
        "        'tokenize_full/total_failed': fail_count,\n",
        "        'tokenize_full/total_time_hours': total_time / 3600,\n",
        "        'tokenize_full/avg_time_per_file': total_time / len(remaining_paths) if remaining_paths else 0,\n",
        "        'tokenize_full/files_per_hour': success_count / (total_time / 3600) if total_time > 0 else 0,\n",
        "    })\n",
        "\n",
        "    # ã‚µãƒãƒªãƒ¼ã‚’è¨­å®š\n",
        "    wandb.run.summary['tokenization_complete'] = True\n",
        "    wandb.run.summary['total_tokenized_files'] = len(existing_tokens) + success_count\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "# ãƒ¡ãƒ¢ãƒªè§£æ”¾\n",
        "del compression_model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "278888dd",
      "metadata": {
        "id": "278888dd"
      },
      "source": [
        "## ã‚»ãƒ« 5 â€” DeepSpeed è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆds_config.json ã‚’ä½œã‚‹ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "650b2f72",
      "metadata": {
        "id": "650b2f72"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "ds_config = {\n",
        "  \"train_batch_size\": 16,\n",
        "  \"train_micro_batch_size_per_gpu\": 2,\n",
        "  \"gradient_accumulation_steps\": 8,\n",
        "  \"optimizer\": {\n",
        "    \"type\": \"AdamW\",\n",
        "    \"params\": {\n",
        "      \"lr\": 1e-4,\n",
        "      \"weight_decay\": 0.01\n",
        "    }\n",
        "  },\n",
        "  \"fp16\": {\n",
        "    \"enabled\": True\n",
        "  },\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 3,\n",
        "    \"offload_optimizer\": {\n",
        "      \"device\": \"cpu\",\n",
        "      \"pin_memory\": True\n",
        "    },\n",
        "    \"offload_param\": {\n",
        "      \"device\": \"cpu\"\n",
        "    },\n",
        "    \"overlap_comm\": True,\n",
        "    \"contiguous_gradients\": True\n",
        "  }\n",
        "}\n",
        "\n",
        "with open('ds_config.json','w') as f:\n",
        "    json.dump(ds_config, f, indent=2)\n",
        "\n",
        "print('ds_config.json ã‚’ä½œæˆã—ã¾ã—ãŸ')\n",
        "!cat ds_config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc72c21b",
      "metadata": {
        "id": "bc72c21b"
      },
      "source": [
        "## ã‚»ãƒ« 6 â€” LoRA æŒ¿å…¥ï¼ˆãƒ¢ãƒ‡ãƒ«å´ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦ï¼‰\n",
        "\n",
        "- æ³¨æ„: audiocraft ã®ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€ã“ã“ã¯**ä¾‹ç¤º**ã€‚`musicgen-large` ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Linear å±¤ã« LoRA ã‚’å½“ã¦ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "474dd8d3",
      "metadata": {
        "id": "474dd8d3"
      },
      "outputs": [],
      "source": [
        "import loralib as lora\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from audiocraft.models import MusicGen\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
        "print('MusicGen-Large ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "model.eval()\n",
        "\n",
        "# LoRA ã‚’é©ç”¨ã™ã‚‹é–¢æ•°\n",
        "def apply_lora_to_linear(module, r=8, lora_alpha=32, lora_dropout=0.1, parent_name=''):\n",
        "    \"\"\"\n",
        "    ãƒ¢ãƒ‡ãƒ«å†…ã®Linearå±¤ã‚’loralibã®Linearå±¤ã«ç½®ãæ›ãˆã‚‹\n",
        "    \"\"\"\n",
        "    for name, child in list(module.named_children()):\n",
        "        full_name = f\"{parent_name}.{name}\" if parent_name else name\n",
        "\n",
        "        if isinstance(child, nn.Linear):\n",
        "            # Linearå±¤ã‚’LoRAä»˜ãLinearã«ç½®ãæ›ãˆ\n",
        "            in_features = child.in_features\n",
        "            out_features = child.out_features\n",
        "            bias = child.bias is not None\n",
        "\n",
        "            # æ–°ã—ã„LoRA Linearå±¤ã‚’ä½œæˆ\n",
        "            lora_linear = lora.Linear(\n",
        "                in_features,\n",
        "                out_features,\n",
        "                r=r,\n",
        "                lora_alpha=lora_alpha,\n",
        "                lora_dropout=lora_dropout,\n",
        "                bias=bias\n",
        "            )\n",
        "\n",
        "            # å…ƒã®é‡ã¿ã‚’ã‚³ãƒ”ãƒ¼\n",
        "            lora_linear.weight.data = child.weight.data.clone()\n",
        "            if bias:\n",
        "                lora_linear.bias.data = child.bias.data.clone()\n",
        "\n",
        "            # ç½®ãæ›ãˆ\n",
        "            setattr(module, name, lora_linear)\n",
        "            print(f'Applied LoRA to: {full_name}')\n",
        "        else:\n",
        "            # å†å¸°çš„ã«å­ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‡¦ç†\n",
        "            apply_lora_to_linear(child, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, parent_name=full_name)\n",
        "\n",
        "# LoRAã‚’é©ç”¨\n",
        "print('\\nLoRAã‚’é©ç”¨ä¸­...')\n",
        "apply_lora_to_linear(model.lm, r=8)  # MusicGenã®è¨€èªãƒ¢ãƒ‡ãƒ«éƒ¨åˆ†ã«LoRAã‚’é©ç”¨\n",
        "\n",
        "# LoRA ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’å­¦ç¿’å¯èƒ½ã«è¨­å®š\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "for name, p in model.named_parameters():\n",
        "    if 'lora_' in name:\n",
        "        p.requires_grad = True\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f'\\nå­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {trainable:,} / å…¨ä½“: {total:,} ({100*trainable/total:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d880f206",
      "metadata": {
        "id": "d880f206"
      },
      "source": [
        "## ã‚»ãƒ« 7 â€” ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³èª­ã¿è¾¼ã¿ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b48b10b7",
      "metadata": {
        "id": "b48b10b7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "class TokenDataset(Dataset):\n",
        "    def __init__(self, token_dir, max_length=1500):\n",
        "        \"\"\"\n",
        "        ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€Dataset\n",
        "\n",
        "        Args:\n",
        "            token_dir: ãƒˆãƒ¼ã‚¯ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "            max_length: ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ€å¤§é•·ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°/åˆ‡ã‚Šè©°ã‚ã«ä½¿ç”¨ï¼‰\n",
        "        \"\"\"\n",
        "        self.files = sorted(list(Path(token_dir).glob('*.pt')))\n",
        "        self.max_length = max_length\n",
        "        print(f'Dataset initialized with {len(self.files)} samples')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # ãƒˆãƒ¼ã‚¯ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "        data = torch.load(self.files[idx])\n",
        "        tokens = data['tokens']  # [B, K, T] å½¢å¼ã‚’æƒ³å®š\n",
        "\n",
        "        # ãƒãƒƒãƒæ¬¡å…ƒã‚’å‰Šé™¤\n",
        "        if tokens.dim() == 3:\n",
        "            tokens = tokens.squeeze(0)  # [K, T]\n",
        "\n",
        "        # é•·ã•ã‚’èª¿æ•´ï¼ˆåˆ‡ã‚Šè©°ã‚ã¾ãŸã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰\n",
        "        seq_len = tokens.shape[-1]\n",
        "        if seq_len > self.max_length:\n",
        "            # ãƒ©ãƒ³ãƒ€ãƒ ãªä½ç½®ã‹ã‚‰åˆ‡ã‚Šå‡ºã—\n",
        "            start = random.randint(0, seq_len - self.max_length)\n",
        "            tokens = tokens[:, start:start + self.max_length]\n",
        "        elif seq_len < self.max_length:\n",
        "            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°\n",
        "            pad_length = self.max_length - seq_len\n",
        "            tokens = torch.nn.functional.pad(tokens, (0, pad_length), value=0)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ä½œæˆ\n",
        "dataset = TokenDataset(TOKEN_DIR, max_length=1500)\n",
        "\n",
        "# è¨“ç·´ç”¨ã¨æ¤œè¨¼ç”¨ã«åˆ†å‰²\n",
        "train_size = int(0.95 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    dataset, [train_size, valid_size]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f'è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(train_dataset)}')\n",
        "print(f'æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73fab6e8",
      "metadata": {
        "id": "73fab6e8"
      },
      "source": [
        "## ã‚»ãƒ« 8 â€” å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆWandB ãƒ­ã‚®ãƒ³ã‚°ä»˜ãï¼‰\n",
        "\n",
        "- DeepSpeed ã‚’ä½¿ã£ãŸå­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
        "- WandB ã§ã®ãƒ­ã‚®ãƒ³ã‚°\n",
        "- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜ã¨å†é–‹æ©Ÿèƒ½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84124322",
      "metadata": {
        "id": "84124322"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from google.colab import userdata\n",
        "import shutil\n",
        "\n",
        "# ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰WandB APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "try:\n",
        "    WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "    # WandBãƒ­ã‚°ã‚¤ãƒ³ï¼ˆæ—¢ã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰\n",
        "    if not wandb.api.api_key:\n",
        "        wandb.login(key=WANDB_API_KEY)\n",
        "\n",
        "    # WandBå®Ÿé¨“ã®åˆæœŸåŒ–\n",
        "    wandb.init(\n",
        "        project='musicgen-lora-finetune',\n",
        "        name=f'run_{time.strftime(\"%Y%m%d_%H%M%S\")}',\n",
        "        config={\n",
        "            'model': 'musicgen-large',\n",
        "            'lora_r': 8,\n",
        "            'lora_alpha': 32,\n",
        "            'learning_rate': 1e-4,\n",
        "            'batch_size': 2,\n",
        "            'gradient_accumulation_steps': 8,\n",
        "            'num_epochs': 5,\n",
        "            'optimizer': 'AdamW',\n",
        "            'weight_decay': 0.01,\n",
        "        },\n",
        "        tags=['musicgen', 'lora', 'a100']\n",
        "    )\n",
        "    use_wandb = True\n",
        "    print('âœ“ WandBãƒ­ã‚®ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ')\n",
        "except Exception as e:\n",
        "    print(f'âš ï¸ WandBåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}')\n",
        "    print('WandBç„¡ã—ã§ç¶šè¡Œã—ã¾ã™')\n",
        "    use_wandb = False\n",
        "\n",
        "# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}')\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã«è»¢é€\n",
        "model = model.to(device)\n",
        "\n",
        "# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ï¼ˆLoRAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ï¼‰\n",
        "optimizer = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "# Google Driveã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "CKPT_DIR = '/content/drive/MyDrive/MusicGen_Checkpoints'\n",
        "LORA_DIR = os.path.join(CKPT_DIR, 'lora_weights')\n",
        "FULL_MODEL_DIR = os.path.join(CKPT_DIR, 'full_models')\n",
        "\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "os.makedirs(LORA_DIR, exist_ok=True)\n",
        "os.makedirs(FULL_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(f'ğŸ“ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å…ˆ:')\n",
        "print(f'   ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {CKPT_DIR}')\n",
        "print(f'   LoRAé‡ã¿: {LORA_DIR}')\n",
        "print(f'   å®Œå…¨ãƒ¢ãƒ‡ãƒ«: {FULL_MODEL_DIR}')\n",
        "\n",
        "latest_ckpt = os.path.join(CKPT_DIR, 'latest.pt')\n",
        "\n",
        "# LoRAé‡ã¿ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°\n",
        "def extract_lora_weights(model):\n",
        "    \"\"\"LoRAå±¤ã®é‡ã¿ã®ã¿ã‚’æŠ½å‡º\"\"\"\n",
        "    lora_state_dict = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'lora_' in name and param.requires_grad:\n",
        "            lora_state_dict[name] = param.cpu().detach().clone()\n",
        "    return lora_state_dict\n",
        "\n",
        "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜é–¢æ•°\n",
        "def save_checkpoint(model, optimizer, epoch, global_step, loss, checkpoint_type='regular'):\n",
        "    \"\"\"\n",
        "    ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜\n",
        "    checkpoint_type: 'regular', 'best', 'epoch', 'step'\n",
        "    \"\"\"\n",
        "    # å®Œå…¨ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'global_step': global_step,\n",
        "        'model_state': model.state_dict(),\n",
        "        'opt_state': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'best_loss': best_loss,\n",
        "        'timestamp': time.strftime(\"%Y%m%d_%H%M%S\"),\n",
        "        'lora_config': {\n",
        "            'r': 8,\n",
        "            'lora_alpha': 32,\n",
        "            'lora_dropout': 0.1,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # LoRAé‡ã¿ã®ã¿ã‚’æŠ½å‡º\n",
        "    lora_weights = extract_lora_weights(model)\n",
        "    lora_checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'global_step': global_step,\n",
        "        'lora_weights': lora_weights,\n",
        "        'loss': loss,\n",
        "        'timestamp': checkpoint['timestamp'],\n",
        "        'lora_config': checkpoint['lora_config'],\n",
        "    }\n",
        "\n",
        "    if checkpoint_type == 'regular':\n",
        "        # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆä¸Šæ›¸ãï¼‰\n",
        "        torch.save(checkpoint, latest_ckpt)\n",
        "        torch.save(lora_checkpoint, os.path.join(LORA_DIR, 'latest_lora.pt'))\n",
        "        print(f'  ğŸ’¾ æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {latest_ckpt}')\n",
        "\n",
        "    elif checkpoint_type == 'best':\n",
        "        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\n",
        "        best_ckpt = os.path.join(FULL_MODEL_DIR, 'best_model.pt')\n",
        "        best_lora = os.path.join(LORA_DIR, 'best_lora.pt')\n",
        "        torch.save(checkpoint, best_ckpt)\n",
        "        torch.save(lora_checkpoint, best_lora)\n",
        "        print(f'  ğŸ† ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜: {best_ckpt}')\n",
        "        print(f'  ğŸ† ãƒ™ã‚¹ãƒˆLoRAä¿å­˜: {best_lora}')\n",
        "\n",
        "    elif checkpoint_type == 'epoch':\n",
        "        # ã‚¨ãƒãƒƒã‚¯ã”ã¨\n",
        "        epoch_ckpt = os.path.join(FULL_MODEL_DIR, f'checkpoint_epoch_{epoch+1}.pt')\n",
        "        epoch_lora = os.path.join(LORA_DIR, f'lora_epoch_{epoch+1}.pt')\n",
        "        torch.save(checkpoint, epoch_ckpt)\n",
        "        torch.save(lora_checkpoint, epoch_lora)\n",
        "        print(f'  ğŸ“Œ ã‚¨ãƒãƒƒã‚¯{epoch+1}ä¿å­˜: {epoch_ckpt}')\n",
        "\n",
        "    elif checkpoint_type == 'step':\n",
        "        # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ï¼ˆä¸­é–“ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼‰\n",
        "        step_ckpt = os.path.join(CKPT_DIR, f'checkpoint_step_{global_step}.pt')\n",
        "        torch.save(checkpoint, step_ckpt)\n",
        "        print(f'  â±ï¸ ã‚¹ãƒ†ãƒƒãƒ—{global_step}ä¿å­˜: {step_ckpt}')\n",
        "\n",
        "    return checkpoint\n",
        "\n",
        "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹\n",
        "start_epoch = 0\n",
        "global_step = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "if os.path.exists(latest_ckpt):\n",
        "    print(f'ğŸ”„ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹: {latest_ckpt}')\n",
        "    ckpt = torch.load(latest_ckpt, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model_state'], strict=False)\n",
        "    optimizer.load_state_dict(ckpt['opt_state'])\n",
        "    start_epoch = ckpt['epoch'] + 1\n",
        "    global_step = ckpt.get('global_step', 0)\n",
        "    best_loss = ckpt.get('best_loss', float('inf'))\n",
        "    print(f'  âœ“ ã‚¨ãƒãƒƒã‚¯ {start_epoch} ã‹ã‚‰å†é–‹')\n",
        "    print(f'  âœ“ ãƒ™ã‚¹ãƒˆæå¤±: {best_loss:.4f}')\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log({'resumed_from_epoch': start_epoch, 'resumed_best_loss': best_loss})\n",
        "\n",
        "# æå¤±é–¢æ•°ï¼ˆå˜ç´”ãªMSEæå¤±ã®ä¾‹ï¼‰\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "num_epochs = 5\n",
        "accum_steps = 8\n",
        "log_interval = 10\n",
        "save_step_interval = 500  # 500ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ä¸­é–“ä¿å­˜\n",
        "\n",
        "# å­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
        "print('\\nğŸš€ å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...\\n')\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    epoch_start_time = time.time()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "    for batch_idx, tokens in enumerate(pbar):\n",
        "        try:\n",
        "            tokens = tokens.to(device)  # [B, K, T]\n",
        "\n",
        "            # ç°¡æ˜“çš„ãªæå¤±è¨ˆç®—ï¼ˆå®Ÿéš›ã®MusicGenã®å­¦ç¿’ã§ã¯ã‚ˆã‚Šè¤‡é›‘ãªå‡¦ç†ãŒå¿…è¦ï¼‰\n",
        "            # ã“ã“ã§ã¯è‡ªå·±å›å¸°çš„ãªäºˆæ¸¬ã‚¿ã‚¹ã‚¯ã‚’æ¨¡å€£\n",
        "            # æ³¨: å®Ÿéš›ã®MusicGenã®å­¦ç¿’ã«ã¯å°‚ç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ãŒå¿…è¦ã§ã™\n",
        "\n",
        "            # ä»®ã®æå¤±è¨ˆç®—ï¼ˆå®Ÿè£…ã¯è¦èª¿æ•´ï¼‰\n",
        "            outputs = model.lm.forward(tokens)\n",
        "            loss = criterion(outputs, tokens.float()) / accum_steps\n",
        "\n",
        "            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "            loss.backward()\n",
        "\n",
        "            # å‹¾é…ç´¯ç©\n",
        "            if (batch_idx + 1) % accum_steps == 0:\n",
        "                # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                    max_norm=1.0\n",
        "                )\n",
        "\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                # WandBãƒ­ã‚®ãƒ³ã‚°\n",
        "                if use_wandb and global_step % log_interval == 0:\n",
        "                    wandb.log({\n",
        "                        'train/loss': loss.item() * accum_steps,\n",
        "                        'train/epoch': epoch,\n",
        "                        'train/step': global_step,\n",
        "                        'train/learning_rate': optimizer.param_groups[0]['lr'],\n",
        "                    }, step=global_step)\n",
        "\n",
        "                # ä¸­é–“ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆå®šæœŸçš„ï¼‰\n",
        "                if global_step % save_step_interval == 0:\n",
        "                    save_checkpoint(model, optimizer, epoch, global_step,\n",
        "                                  loss.item() * accum_steps, checkpoint_type='step')\n",
        "\n",
        "            epoch_loss += loss.item() * accum_steps\n",
        "            pbar.set_postfix({'loss': f'{loss.item() * accum_steps:.4f}'})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'\\nâŒ ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}')\n",
        "            continue\n",
        "\n",
        "    # ã‚¨ãƒãƒƒã‚¯çµ‚äº†æ™‚ã®å‡¦ç†\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f'\\nâœ… Epoch {epoch+1} å®Œäº† - å¹³å‡æå¤±: {avg_loss:.4f} - æ™‚é–“: {epoch_time:.2f}ç§’')\n",
        "\n",
        "    # WandBã«ã‚¨ãƒãƒƒã‚¯ã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°\n",
        "    if use_wandb:\n",
        "        epoch_metrics = {\n",
        "            'epoch/avg_loss': avg_loss,\n",
        "            'epoch/time': epoch_time,\n",
        "            'epoch/number': epoch + 1,\n",
        "        }\n",
        "\n",
        "        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‹ãƒã‚§ãƒƒã‚¯\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            epoch_metrics['epoch/best_loss'] = best_loss\n",
        "            epoch_metrics['epoch/is_best'] = True\n",
        "        else:\n",
        "            epoch_metrics['epoch/is_best'] = False\n",
        "\n",
        "        wandb.log(epoch_metrics, step=global_step)\n",
        "\n",
        "    # æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆæ¯ã‚¨ãƒãƒƒã‚¯ï¼‰\n",
        "    save_checkpoint(model, optimizer, epoch, global_step, avg_loss, checkpoint_type='regular')\n",
        "\n",
        "    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜\n",
        "    save_checkpoint(model, optimizer, epoch, global_step, avg_loss, checkpoint_type='epoch')\n",
        "\n",
        "    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜\n",
        "    if avg_loss == best_loss:\n",
        "        save_checkpoint(model, optimizer, epoch, global_step, avg_loss, checkpoint_type='best')\n",
        "\n",
        "        if use_wandb:\n",
        "            # WandBã«ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜\n",
        "            artifact = wandb.Artifact(\n",
        "                name=f'musicgen-lora-best-epoch{epoch+1}',\n",
        "                type='model',\n",
        "                description=f'Best MusicGen LoRA model at epoch {epoch+1}',\n",
        "                metadata={\n",
        "                    'epoch': epoch + 1,\n",
        "                    'loss': avg_loss,\n",
        "                    'global_step': global_step,\n",
        "                }\n",
        "            )\n",
        "            best_lora_path = os.path.join(LORA_DIR, 'best_lora.pt')\n",
        "            artifact.add_file(best_lora_path)\n",
        "            wandb.log_artifact(artifact)\n",
        "            print(f'  ğŸ“¤ WandBã«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰')\n",
        "\n",
        "# å­¦ç¿’å®Œäº†å¾Œã®æœ€çµ‚ä¿å­˜\n",
        "print('\\n' + '='*60)\n",
        "print('ğŸ‰ å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼')\n",
        "print('='*60)\n",
        "\n",
        "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜\n",
        "final_ckpt = os.path.join(FULL_MODEL_DIR, 'final_model.pt')\n",
        "final_lora = os.path.join(LORA_DIR, 'final_lora.pt')\n",
        "\n",
        "final_checkpoint = {\n",
        "    'epoch': num_epochs - 1,\n",
        "    'global_step': global_step,\n",
        "    'model_state': model.state_dict(),\n",
        "    'opt_state': optimizer.state_dict(),\n",
        "    'loss': avg_loss,\n",
        "    'best_loss': best_loss,\n",
        "    'timestamp': time.strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    'lora_config': {'r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1},\n",
        "}\n",
        "\n",
        "final_lora_checkpoint = {\n",
        "    'epoch': num_epochs - 1,\n",
        "    'global_step': global_step,\n",
        "    'lora_weights': extract_lora_weights(model),\n",
        "    'loss': avg_loss,\n",
        "    'best_loss': best_loss,\n",
        "    'timestamp': final_checkpoint['timestamp'],\n",
        "    'lora_config': final_checkpoint['lora_config'],\n",
        "}\n",
        "\n",
        "torch.save(final_checkpoint, final_ckpt)\n",
        "torch.save(final_lora_checkpoint, final_lora)\n",
        "\n",
        "print(f'\\nğŸ“¦ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜:')\n",
        "print(f'  å®Œå…¨ãƒ¢ãƒ‡ãƒ«: {final_ckpt}')\n",
        "print(f'  LoRAé‡ã¿: {final_lora}')\n",
        "\n",
        "# ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n",
        "print(f'\\nğŸ“‚ ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:')\n",
        "print(f'\\n  ã€å®Œå…¨ãƒ¢ãƒ‡ãƒ«ã€‘ ({FULL_MODEL_DIR})')\n",
        "for f in sorted(Path(FULL_MODEL_DIR).glob('*.pt')):\n",
        "    size_mb = f.stat().st_size / (1024 * 1024)\n",
        "    print(f'    - {f.name} ({size_mb:.1f} MB)')\n",
        "\n",
        "print(f'\\n  ã€LoRAé‡ã¿ã®ã¿ã€‘ ({LORA_DIR})')\n",
        "for f in sorted(Path(LORA_DIR).glob('*.pt')):\n",
        "    size_mb = f.stat().st_size / (1024 * 1024)\n",
        "    print(f'    - {f.name} ({size_mb:.1f} MB)')\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.log({'training/completed': True, 'training/final_loss': avg_loss})\n",
        "\n",
        "    # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚‚ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜\n",
        "    final_artifact = wandb.Artifact(\n",
        "        name='musicgen-lora-final',\n",
        "        type='model',\n",
        "        description='Final MusicGen LoRA model after all epochs',\n",
        "        metadata={\n",
        "            'epochs': num_epochs,\n",
        "            'final_loss': avg_loss,\n",
        "            'best_loss': best_loss,\n",
        "            'global_step': global_step,\n",
        "        }\n",
        "    )\n",
        "    final_artifact.add_file(final_lora)\n",
        "    wandb.log_artifact(final_artifact)\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "print(f'\\nâœ… ã™ã¹ã¦ã®é‡ã¿ãŒGoogle Driveã«ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼')\n",
        "print(f'   ğŸ“ å ´æ‰€: {CKPT_DIR}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8fde84f",
      "metadata": {
        "id": "e8fde84f"
      },
      "source": [
        "## ã‚»ãƒ« 9 â€” æ¨å¥¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé–‹å§‹ç‚¹ï¼‰\n",
        "\n",
        "- LoRA rank: `r = 8`ï¼ˆå¿…è¦ãªã‚‰ 16ï¼‰\n",
        "- Learning rate (LoRA): `1e-4`\n",
        "- micro_batch_per_gpu: `2`\n",
        "- grad_accum: `8` (å®ŸåŠ¹ãƒãƒƒãƒ = 16)\n",
        "- epochs: `3~10`ï¼ˆã¾ãš 3 ã§ç¢ºèªï¼‰\n",
        "- ä¿å­˜: `latest.pt`ï¼ˆä¸Šæ›¸ãï¼‰ + `ckpt_ep{n}.pt`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf84f64",
      "metadata": {
        "id": "5cf84f64"
      },
      "source": [
        "## ã‚»ãƒ« 10 â€” æ¥½æ›²ç”Ÿæˆï¼ˆå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ã®æ¨è«–ï¼‰\n",
        "\n",
        "å­¦ç¿’ã—ãŸLoRAãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ¥½æ›²ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574bde50",
      "metadata": {
        "id": "574bde50"
      },
      "outputs": [],
      "source": [
        "from audiocraft.models import MusicGen\n",
        "from audiocraft.data.audio import audio_write\n",
        "from IPython.display import Audio, display\n",
        "import torch\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print('='*60)\n",
        "print('ğŸµ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ã®æ¥½æ›²ç”Ÿæˆ')\n",
        "print('='*60)\n",
        "\n",
        "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "CKPT_DIR = '/content/drive/MyDrive/MusicGen_Checkpoints'\n",
        "LORA_DIR = os.path.join(CKPT_DIR, 'lora_weights')\n",
        "FULL_MODEL_DIR = os.path.join(CKPT_DIR, 'full_models')\n",
        "\n",
        "# åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèª\n",
        "print('\\nğŸ“‚ åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:')\n",
        "available_checkpoints = {}\n",
        "\n",
        "if os.path.exists(FULL_MODEL_DIR):\n",
        "    full_models = list(Path(FULL_MODEL_DIR).glob('*.pt'))\n",
        "    if full_models:\n",
        "        print('\\n  å®Œå…¨ãƒ¢ãƒ‡ãƒ«:')\n",
        "        for i, ckpt in enumerate(sorted(full_models)):\n",
        "            size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
        "            available_checkpoints[ckpt.stem] = str(ckpt)\n",
        "            print(f'    {i+1}. {ckpt.name} ({size_mb:.1f} MB)')\n",
        "\n",
        "if os.path.exists(LORA_DIR):\n",
        "    lora_models = list(Path(LORA_DIR).glob('*.pt'))\n",
        "    if lora_models:\n",
        "        print('\\n  LoRAé‡ã¿ã®ã¿:')\n",
        "        for i, ckpt in enumerate(sorted(lora_models)):\n",
        "            size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
        "            print(f'    {i+1}. {ckpt.name} ({size_mb:.1f} MB)')\n",
        "\n",
        "# ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠï¼ˆå„ªå…ˆé †ä½: best > final > latestï¼‰\n",
        "checkpoint_to_load = None\n",
        "checkpoint_type = None\n",
        "\n",
        "# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å„ªå…ˆ\n",
        "best_model = os.path.join(FULL_MODEL_DIR, 'best_model.pt')\n",
        "if os.path.exists(best_model):\n",
        "    checkpoint_to_load = best_model\n",
        "    checkpoint_type = 'best'\n",
        "    print(f'\\nâœ… ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨: {best_model}')\n",
        "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«\n",
        "elif os.path.exists(os.path.join(FULL_MODEL_DIR, 'final_model.pt')):\n",
        "    checkpoint_to_load = os.path.join(FULL_MODEL_DIR, 'final_model.pt')\n",
        "    checkpoint_type = 'final'\n",
        "    print(f'\\nâœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨: {checkpoint_to_load}')\n",
        "# æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ\n",
        "elif os.path.exists(os.path.join(CKPT_DIR, 'latest.pt')):\n",
        "    checkpoint_to_load = os.path.join(CKPT_DIR, 'latest.pt')\n",
        "    checkpoint_type = 'latest'\n",
        "    print(f'\\nâœ… æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨: {checkpoint_to_load}')\n",
        "else:\n",
        "    print('\\nâš ï¸ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚')\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
        "print('\\nğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...')\n",
        "\n",
        "if checkpoint_to_load:\n",
        "    # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "    print('  âœ“ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†')\n",
        "\n",
        "    # LoRAã‚’å†é©ç”¨\n",
        "    def apply_lora_to_linear(module, r=8, lora_alpha=32, lora_dropout=0.1, parent_name=''):\n",
        "        import loralib as lora\n",
        "        import torch.nn as nn\n",
        "\n",
        "        for name, child in list(module.named_children()):\n",
        "            full_name = f\"{parent_name}.{name}\" if parent_name else name\n",
        "\n",
        "            if isinstance(child, nn.Linear):\n",
        "                in_features = child.in_features\n",
        "                out_features = child.out_features\n",
        "                bias = child.bias is not None\n",
        "\n",
        "                lora_linear = lora.Linear(\n",
        "                    in_features, out_features, r=r,\n",
        "                    lora_alpha=lora_alpha, lora_dropout=lora_dropout, bias=bias\n",
        "                )\n",
        "                lora_linear.weight.data = child.weight.data.clone()\n",
        "                if bias:\n",
        "                    lora_linear.bias.data = child.bias.data.clone()\n",
        "\n",
        "                setattr(module, name, lora_linear)\n",
        "            else:\n",
        "                apply_lora_to_linear(child, r=r, lora_alpha=lora_alpha,\n",
        "                                   lora_dropout=lora_dropout, parent_name=full_name)\n",
        "\n",
        "    apply_lora_to_linear(model.lm, r=8)\n",
        "    print('  âœ“ LoRAå±¤é©ç”¨å®Œäº†')\n",
        "\n",
        "    # å­¦ç¿’æ¸ˆã¿é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "    ckpt = torch.load(checkpoint_to_load, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model_state'], strict=False)\n",
        "\n",
        "    print(f'  âœ“ å­¦ç¿’æ¸ˆã¿é‡ã¿ãƒ­ãƒ¼ãƒ‰å®Œäº†')\n",
        "    print(f'     ã‚¨ãƒãƒƒã‚¯: {ckpt.get(\"epoch\", \"ä¸æ˜\") + 1}')\n",
        "    print(f'     æå¤±: {ckpt.get(\"loss\", \"ä¸æ˜\")}')\n",
        "    print(f'     ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {ckpt.get(\"timestamp\", \"ä¸æ˜\")}')\n",
        "else:\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-large')\n",
        "    print('  âœ“ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’ãƒ­ãƒ¼ãƒ‰')\n",
        "\n",
        "model = model.to('cuda')\n",
        "model.eval()\n",
        "print('\\nâœ… ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†\\n')\n",
        "\n",
        "# ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š\n",
        "model.set_generation_params(\n",
        "    use_sampling=True,\n",
        "    top_k=250,\n",
        "    top_p=0.0,\n",
        "    temperature=1.0,\n",
        "    duration=30,  # 30ç§’ã®æ¥½æ›²ã‚’ç”Ÿæˆ\n",
        "    cfg_coef=3.0,  # Classifier-free guidanceä¿‚æ•°\n",
        ")\n",
        "\n",
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­å®š\n",
        "descriptions = [\n",
        "    \"A dynamic heavy metal song with fast drums and guitar solo\",\n",
        "    \"Relaxing jazz piano with soft background ambience\",\n",
        "    \"Upbeat electronic dance music with strong bass\",\n",
        "]\n",
        "\n",
        "print('ğŸ¼ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:')\n",
        "for i, desc in enumerate(descriptions):\n",
        "    print(f'  {i+1}. {desc}')\n",
        "\n",
        "print('\\nğŸµ æ¥½æ›²ã‚’ç”Ÿæˆä¸­...')\n",
        "with torch.no_grad():\n",
        "    wav = model.generate(descriptions)\n",
        "\n",
        "print('âœ… ç”Ÿæˆå®Œäº†ï¼\\n')\n",
        "\n",
        "# ç”Ÿæˆã•ã‚ŒãŸæ¥½æ›²ã‚’ä¿å­˜ãƒ»å†ç”Ÿ\n",
        "output_dir = '/content/generated_music'\n",
        "drive_output_dir = '/content/drive/MyDrive/MusicGen_Generated'\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(drive_output_dir, exist_ok=True)\n",
        "\n",
        "print('ğŸ’¾ æ¥½æ›²ã‚’ä¿å­˜ä¸­...')\n",
        "\n",
        "for idx, one_wav in enumerate(wav):\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜\n",
        "    local_filename = os.path.join(output_dir, f\"generated_{idx}_{timestamp}\")\n",
        "    audio_write(\n",
        "        local_filename,\n",
        "        one_wav.cpu(),\n",
        "        model.sample_rate,\n",
        "        strategy=\"loudness\",\n",
        "        loudness_compressor=True\n",
        "    )\n",
        "\n",
        "    # Google Driveã«ã‚‚ä¿å­˜\n",
        "    drive_filename = os.path.join(drive_output_dir, f\"generated_{idx}_{timestamp}\")\n",
        "    audio_write(\n",
        "        drive_filename,\n",
        "        one_wav.cpu(),\n",
        "        model.sample_rate,\n",
        "        strategy=\"loudness\",\n",
        "        loudness_compressor=True\n",
        "    )\n",
        "\n",
        "    print(f'\\n  æ¥½æ›² {idx + 1}:')\n",
        "    print(f'    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {descriptions[idx]}')\n",
        "    print(f'    ãƒ­ãƒ¼ã‚«ãƒ«: {local_filename}.wav')\n",
        "    print(f'    Drive: {drive_filename}.wav')\n",
        "\n",
        "    # Colabä¸Šã§å†ç”Ÿ\n",
        "    print(f'    ğŸ”Š å†ç”Ÿ:')\n",
        "    display(Audio(local_filename + \".wav\", rate=model.sample_rate))\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('âœ… ã™ã¹ã¦ã®æ¥½æ›²ãŒç”Ÿæˆã•ã‚Œã€Google Driveã«ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼')\n",
        "print(f'ğŸ“ ä¿å­˜å…ˆ: {drive_output_dir}')\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c24c60",
      "metadata": {
        "id": "e4c24c60"
      },
      "source": [
        "## ä¾¿åˆ©ãªé‹ç”¨ãƒ¡ãƒ¢\n",
        "\n",
        "- æœ€åˆã«å¿…ãš **å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ100ã€œ500ï¼‰** ã§ end-to-end ã‚’å›ã—ã¦ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã€‚WandB ã«éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚¢ãƒƒãƒ—ã—ã¦ç¢ºèªã™ã‚‹ã€‚  \n",
        "- ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¯ä¸¦åˆ—åŒ–ã—ã¦äº‹å‰ã«æ¸ˆã¾ã›ã‚‹ï¼ˆI/O ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã®æ©æµãŒå¤§ãã„ï¼‰ã€‚  \n",
        "- DeepSpeed ã® offload ã‚’æ´»ç”¨ã™ã‚‹ã¨ A100 1 å°ã§ã‚‚å¤§æŠµã® LoRA å­¦ç¿’ã¯å›ã›ã‚‹ã€‚\n",
        "- `fp16` / `bf16` ã®åˆ‡ã‚Šæ›¿ãˆã¯ PyTorch ã¨ GPU ã®ã‚µãƒãƒ¼ãƒˆçŠ¶æ³ã«åˆã‚ã›ã¦ã€‚bf16 ã®æ–¹ãŒæ•°å€¤å®‰å®šæ€§è‰¯å¥½ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "ä»¥ä¸Šã§è¨­å®šã¯å®Œäº†ã§ã™ã€‚é ‘å¼µã£ã¦ãã ã•ã„ï¼ ğŸ¶ğŸ’ª"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cb87518",
      "metadata": {
        "id": "4cb87518"
      },
      "source": [
        "## ã‚»ãƒ« 11 â€” ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
        "\n",
        "Google Driveã«ä¿å­˜ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèªã€å‰Šé™¤ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abff91f1",
      "metadata": {
        "id": "abff91f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "CKPT_DIR = '/content/drive/MyDrive/MusicGen_Checkpoints'\n",
        "LORA_DIR = os.path.join(CKPT_DIR, 'lora_weights')\n",
        "FULL_MODEL_DIR = os.path.join(CKPT_DIR, 'full_models')\n",
        "\n",
        "print('='*60)\n",
        "print('ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†')\n",
        "print('='*60)\n",
        "\n",
        "# 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ…å ±ã®è¡¨ç¤º\n",
        "def get_dir_size(path):\n",
        "    \"\"\"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—\"\"\"\n",
        "    total = 0\n",
        "    for entry in Path(path).rglob('*'):\n",
        "        if entry.is_file():\n",
        "            total += entry.stat().st_size\n",
        "    return total\n",
        "\n",
        "def format_size(size_bytes):\n",
        "    \"\"\"ãƒã‚¤ãƒˆã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›\"\"\"\n",
        "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
        "        if size_bytes < 1024.0:\n",
        "            return f\"{size_bytes:.2f} {unit}\"\n",
        "        size_bytes /= 1024.0\n",
        "    return f\"{size_bytes:.2f} TB\"\n",
        "\n",
        "print('\\nğŸ“Š ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ…å ±:')\n",
        "if os.path.exists(CKPT_DIR):\n",
        "    total_size = get_dir_size(CKPT_DIR)\n",
        "    print(f'\\n  å…¨ä½“: {format_size(total_size)}')\n",
        "\n",
        "    if os.path.exists(FULL_MODEL_DIR):\n",
        "        full_size = get_dir_size(FULL_MODEL_DIR)\n",
        "        print(f'  å®Œå…¨ãƒ¢ãƒ‡ãƒ«: {format_size(full_size)}')\n",
        "\n",
        "    if os.path.exists(LORA_DIR):\n",
        "        lora_size = get_dir_size(LORA_DIR)\n",
        "        print(f'  LoRAé‡ã¿: {format_size(lora_size)}')\n",
        "else:\n",
        "    print('  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')\n",
        "\n",
        "# 2. ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®è©³ç´°è¡¨ç¤º\n",
        "print('\\nğŸ“‚ ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:')\n",
        "\n",
        "if os.path.exists(FULL_MODEL_DIR):\n",
        "    print('\\n  ã€å®Œå…¨ãƒ¢ãƒ‡ãƒ«ã€‘')\n",
        "    full_models = sorted(Path(FULL_MODEL_DIR).glob('*.pt'))\n",
        "    if full_models:\n",
        "        for ckpt in full_models:\n",
        "            size = format_size(ckpt.stat().st_size)\n",
        "            mtime = ckpt.stat().st_mtime\n",
        "            import datetime\n",
        "            timestamp = datetime.datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            print(f'    {ckpt.name}')\n",
        "            print(f'      ã‚µã‚¤ã‚º: {size}')\n",
        "            print(f'      æ›´æ–°æ—¥æ™‚: {timestamp}')\n",
        "    else:\n",
        "        print('    ãªã—')\n",
        "\n",
        "if os.path.exists(LORA_DIR):\n",
        "    print('\\n  ã€LoRAé‡ã¿ã€‘')\n",
        "    lora_models = sorted(Path(LORA_DIR).glob('*.pt'))\n",
        "    if lora_models:\n",
        "        for ckpt in lora_models:\n",
        "            size = format_size(ckpt.stat().st_size)\n",
        "            mtime = ckpt.stat().st_mtime\n",
        "            timestamp = datetime.datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            print(f'    {ckpt.name}')\n",
        "            print(f'      ã‚µã‚¤ã‚º: {size}')\n",
        "            print(f'      æ›´æ–°æ—¥æ™‚: {timestamp}')\n",
        "    else:\n",
        "        print('    ãªã—')\n",
        "\n",
        "# 3. å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³\n",
        "print('\\n' + '='*60)\n",
        "print('ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³')\n",
        "print('='*60)\n",
        "\n",
        "# ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆbestã¨finalä»¥å¤–ï¼‰ã‚’å‰Šé™¤ã™ã‚‹ã‹ã©ã†ã‹\n",
        "CLEANUP_OLD_EPOCHS = False  # Trueã«è¨­å®šã™ã‚‹ã¨å¤ã„ã‚¨ãƒãƒƒã‚¯ã‚’å‰Šé™¤\n",
        "\n",
        "if CLEANUP_OLD_EPOCHS:\n",
        "    print('\\nâš ï¸ å¤ã„ã‚¨ãƒãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ä¸­...')\n",
        "\n",
        "    # ä¿æŒã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«\n",
        "    keep_files = {'best_model.pt', 'final_model.pt', 'latest.pt'}\n",
        "\n",
        "    deleted_count = 0\n",
        "    freed_space = 0\n",
        "\n",
        "    for ckpt in Path(FULL_MODEL_DIR).glob('checkpoint_epoch_*.pt'):\n",
        "        if ckpt.name not in keep_files:\n",
        "            size = ckpt.stat().st_size\n",
        "            ckpt.unlink()\n",
        "            deleted_count += 1\n",
        "            freed_space += size\n",
        "            print(f'  âœ“ å‰Šé™¤: {ckpt.name} ({format_size(size)})')\n",
        "\n",
        "    print(f'\\n  å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {deleted_count}')\n",
        "    print(f'  è§£æ”¾ã•ã‚ŒãŸã‚¹ãƒšãƒ¼ã‚¹: {format_size(freed_space)}')\n",
        "else:\n",
        "    print('\\n  ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¯ç„¡åŠ¹ã§ã™ã€‚')\n",
        "    print('  å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ã™ã‚‹å ´åˆã¯ã€CLEANUP_OLD_EPOCHS = True ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚')\n",
        "\n",
        "# 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ\n",
        "print('\\n' + '='*60)\n",
        "print('ğŸ’¼ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³')\n",
        "print('='*60)\n",
        "\n",
        "CREATE_BACKUP = False  # Trueã«è¨­å®šã™ã‚‹ã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ\n",
        "\n",
        "if CREATE_BACKUP:\n",
        "    import datetime\n",
        "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    backup_dir = f'/content/drive/MyDrive/MusicGen_Backups/backup_{timestamp}'\n",
        "\n",
        "    print(f'\\nğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆä¸­: {backup_dir}')\n",
        "\n",
        "    if os.path.exists(CKPT_DIR):\n",
        "        shutil.copytree(CKPT_DIR, backup_dir)\n",
        "        backup_size = get_dir_size(backup_dir)\n",
        "        print(f'  âœ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†')\n",
        "        print(f'  ã‚µã‚¤ã‚º: {format_size(backup_size)}')\n",
        "        print(f'  å ´æ‰€: {backup_dir}')\n",
        "    else:\n",
        "        print('  âš ï¸ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')\n",
        "else:\n",
        "    print('\\n  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ç„¡åŠ¹ã§ã™ã€‚')\n",
        "    print('  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã™ã‚‹å ´åˆã¯ã€CREATE_BACKUP = True ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚')\n",
        "\n",
        "# 5. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã®èª­ã¿è¾¼ã¿\n",
        "print('\\n' + '='*60)\n",
        "print('ğŸ“‹ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè©³ç´°æƒ…å ±')\n",
        "print('='*60)\n",
        "\n",
        "def load_checkpoint_info(ckpt_path):\n",
        "    \"\"\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€\"\"\"\n",
        "    try:\n",
        "        import torch\n",
        "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "        info = {\n",
        "            'epoch': ckpt.get('epoch', 'N/A'),\n",
        "            'global_step': ckpt.get('global_step', 'N/A'),\n",
        "            'loss': ckpt.get('loss', 'N/A'),\n",
        "            'best_loss': ckpt.get('best_loss', 'N/A'),\n",
        "            'timestamp': ckpt.get('timestamp', 'N/A'),\n",
        "        }\n",
        "        return info\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±\n",
        "best_model_path = os.path.join(FULL_MODEL_DIR, 'best_model.pt')\n",
        "if os.path.exists(best_model_path):\n",
        "    print('\\nğŸ† ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«:')\n",
        "    info = load_checkpoint_info(best_model_path)\n",
        "    for key, value in info.items():\n",
        "        print(f'  {key}: {value}')\n",
        "\n",
        "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±\n",
        "final_model_path = os.path.join(FULL_MODEL_DIR, 'final_model.pt')\n",
        "if os.path.exists(final_model_path):\n",
        "    print('\\nğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«:')\n",
        "    info = load_checkpoint_info(final_model_path)\n",
        "    for key, value in info.items():\n",
        "        print(f'  {key}: {value}')\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('âœ… ãƒ¢ãƒ‡ãƒ«ç®¡ç†å®Œäº†')\n",
        "print('='*60)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}